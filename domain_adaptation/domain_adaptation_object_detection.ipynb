{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f17835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b598f060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST  mnist_m\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72ab74e1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ubuntu/.cache/torch/hub/ultralytics_yolov5_master\n",
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "YOLOv5 ðŸš€ 2022-3-28 torch 1.11.0+cu102 CUDA:0 (Tesla T4, 15110MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoShape(\n",
       "  (model): DetectMultiBackend(\n",
       "    (model): Model(\n",
       "      (model): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Conv(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (4): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): Conv(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (6): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): Conv(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (8): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): SPPF(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (10): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (11): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (12): Concat()\n",
       "        (13): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (14): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (15): Upsample(scale_factor=2.0, mode=nearest)\n",
       "        (16): Concat()\n",
       "        (17): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (18): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (19): Concat()\n",
       "        (20): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (21): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (22): Concat()\n",
       "        (23): C3(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (24): Detect(\n",
       "          (m): ModuleList(\n",
       "            (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5161a5d3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (act): SiLU(inplace=True)\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#list(model.named_parameters())\n",
    "print(model.model.model.model[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba224b",
   "metadata": {},
   "source": [
    "### Domain Adaptive YOLOv5s Network\n",
    "\n",
    "The goal of this section is to introduce Gradient Reversal Layers (GRLs) into the YOLOv5s network.  The proposed architecture is based on MS_DAYOLO from [MULTISCALE DOMAIN ADAPTIVE YOLO FOR CROSS-DOMAIN OBJECT DETECTION](https://arxiv.org/pdf/2106.01483v2.pdf):\n",
    "\n",
    "![MS-DAYOLO](MS-DAYOLO.png)\n",
    "\n",
    "The following diagram shows more descriptive gradient flow on a YOLOv5s architecture diagram:\n",
    "\n",
    "![YOLOv5s_w_DA](Yolov5_Arch_w_DA.png)\n",
    "\n",
    "GRLs need to be added after each of the following:\n",
    "\n",
    "model.model.model.model[4] <span style=\"color: red;\">**-> F1** </span><br>\n",
    "model.model.model.model[6] <span style=\"color: red;\">**-> F2**</span>\n",
    "<br>\n",
    "model.model.model.model[8] <span style=\"color: red;\">**-> F3**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114b11de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MS_DAYOLOv5(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module):\n",
    "        super(DAYOLO, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        \n",
    "    def forward(self, input_images: torch.Tensor):\n",
    "        return backbone(input_images, image_size=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToBeHooked(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToBeHooked, self).__init__()\n",
    "        self.a = nn.Sequential(\n",
    "            nn.Linear(1,3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.b = nn.Sequential(\n",
    "            nn.Linear(3,5),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.c = nn.Linear(5,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.a(x)\n",
    "        out = self.b(out)\n",
    "        out = self.c(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "hook_me = ToBeHooked()\n",
    "hook_me\n",
    "for name, m in model.named_modules():\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fddb83ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'out_channels' and 'kernel_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfhooks:\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKey: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m new_model \u001b[38;5;241m=\u001b[39m \u001b[43mNewModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)   \n\u001b[1;32m     79\u001b[0m new_model\u001b[38;5;241m.\u001b[39mavailable_layers()\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mNewModel.__init__\u001b[0;34m(self, backbone, output_layers)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone \u001b[38;5;241m=\u001b[39m backbone\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layers \u001b[38;5;241m=\u001b[39m output_layers\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf1_domain_classifier \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselected_out \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfhooks \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'out_channels' and 'kernel_size'"
     ]
    }
   ],
   "source": [
    "#for param in hook_me.b[0].parameters():\n",
    "    #print(param)\n",
    "    #mul = param*torch.ones(1,5)\n",
    "    #print(f'Result: {mul}')\n",
    "#parallel_out = hook_me.b(torch.ones(1,3))\n",
    "\n",
    "# for GRL\n",
    "from torch.autograd import Function\n",
    "\n",
    "class GradientReversalFn(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        # Store context for backprop\n",
    "        ctx.alpha = alpha\n",
    "        \n",
    "        # Forward pass is a no-op\n",
    "        return x.view_as(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Backward pass is just to -alpha the gradient\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        \n",
    "        # Must return same number as inputs to forward()\n",
    "        return output, None\n",
    "\n",
    "    \n",
    "class NewModel(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module, output_layers):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.output_layers = output_layers\n",
    "        self.f1_domain_classifier = nn.Sequential(\n",
    "            nn.Conv2d(64,)\n",
    "        )\n",
    "        self.selected_out = OrderedDict()\n",
    "        self.fhooks = []\n",
    "        \n",
    "        #print(list(self.backbone.model.model.model._modules.keys()))\n",
    "        \n",
    "        for i,l in enumerate(list(self.backbone.model.model.model._modules.keys())):\n",
    "            if i in self.output_layers:\n",
    "                self.fhooks.append(getattr(self.backbone.model.model.model,l).register_forward_hook(self.forward_hook(l)))\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward_hook(self, layer_name):\n",
    "        def hook(module, input, output):\n",
    "            self.selected_out[layer_name] = output\n",
    "        \n",
    "        return hook\n",
    "    \n",
    "    def forward(self, x, grl_lambda):\n",
    "        \n",
    "        org_out = self.backbone(x)\n",
    "        \n",
    "        f1 = self.selected_out['4']\n",
    "        grl_f1 = GradientReversalFn.apply(f1, grl_lambda)\n",
    "        \n",
    "        \n",
    "        f2 = self.selected_out['6']\n",
    "        frl_f2 = GradientReversalFn.apply(f2, grl_lambda)\n",
    "        \n",
    "        \n",
    "        f3 = self.selected_out['8']\n",
    "        grl_f3 = GradientReversalFn.apply(f3, grl_lambda)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return org_out\n",
    "    \n",
    "    def available_layers(self):\n",
    "        print(len(self.fhooks))\n",
    "        for key in self.fhooks:\n",
    "            print(f'Key: {key}')\n",
    "        \n",
    "\n",
    "new_model = NewModel(model, output_layers=[4,6,8]).to(device)   \n",
    "new_model.available_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6460166",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[4.24362e+00, 4.57453e+00, 8.15290e+00,  ..., 9.65173e-04, 8.05810e-04, 3.39554e-03],\n",
       "         [1.46842e+01, 5.75970e+00, 2.99006e+01,  ..., 1.05029e-03, 1.01106e-03, 3.56276e-03],\n",
       "         [1.81727e+01, 6.26491e+00, 3.34709e+01,  ..., 1.28024e-03, 9.63305e-04, 2.63005e-03],\n",
       "         ...,\n",
       "         [4.02660e+02, 5.99369e+02, 1.47434e+02,  ..., 8.15852e-03, 1.15201e-03, 1.47859e-03],\n",
       "         [4.28607e+02, 6.03118e+02, 1.07851e+02,  ..., 1.08494e-02, 1.43204e-03, 1.72749e-03],\n",
       "         [4.53029e+02, 6.14867e+02, 1.13424e+02,  ..., 9.98767e-03, 1.52228e-03, 1.87308e-03]],\n",
       "\n",
       "        [[4.44466e+00, 4.20125e+00, 8.98019e+00,  ..., 1.28940e-03, 7.14943e-04, 3.46511e-03],\n",
       "         [1.20348e+01, 4.62148e+00, 2.42056e+01,  ..., 1.89548e-03, 8.95789e-04, 3.31240e-03],\n",
       "         [1.79566e+01, 4.39180e+00, 3.05288e+01,  ..., 1.58493e-03, 9.73017e-04, 4.37087e-03],\n",
       "         ...,\n",
       "         [4.03375e+02, 5.99171e+02, 1.48627e+02,  ..., 9.31490e-03, 1.43981e-03, 2.04229e-03],\n",
       "         [4.27087e+02, 6.01187e+02, 1.10042e+02,  ..., 1.33697e-02, 1.57579e-03, 2.05672e-03],\n",
       "         [4.54306e+02, 6.11844e+02, 1.07080e+02,  ..., 1.17325e-02, 1.72844e-03, 2.08972e-03]],\n",
       "\n",
       "        [[5.10908e+00, 3.18375e+00, 1.02354e+01,  ..., 1.44568e-03, 8.74769e-04, 3.68200e-03],\n",
       "         [9.95321e+00, 3.53087e+00, 2.07747e+01,  ..., 1.75858e-03, 9.74217e-04, 3.53589e-03],\n",
       "         [1.72253e+01, 3.40774e+00, 3.17279e+01,  ..., 2.18209e-03, 8.60327e-04, 4.56881e-03],\n",
       "         ...,\n",
       "         [4.03138e+02, 5.98822e+02, 1.49881e+02,  ..., 1.05673e-02, 1.12788e-03, 1.43388e-03],\n",
       "         [4.22669e+02, 6.02549e+02, 1.18927e+02,  ..., 1.25725e-02, 1.21841e-03, 1.76952e-03],\n",
       "         [4.58804e+02, 6.14929e+02, 1.18264e+02,  ..., 1.05151e-02, 1.45681e-03, 1.73182e-03]],\n",
       "\n",
       "        [[4.45227e+00, 4.69372e+00, 8.76591e+00,  ..., 8.21255e-04, 9.81836e-04, 4.85564e-03],\n",
       "         [9.78834e+00, 4.43527e+00, 1.83554e+01,  ..., 9.07201e-04, 9.37773e-04, 3.60673e-03],\n",
       "         [1.68080e+01, 4.33832e+00, 2.77546e+01,  ..., 1.19005e-03, 9.64379e-04, 5.79089e-03],\n",
       "         ...,\n",
       "         [4.02941e+02, 5.99447e+02, 1.50949e+02,  ..., 8.98329e-03, 1.38167e-03, 1.97430e-03],\n",
       "         [4.27068e+02, 6.03899e+02, 1.10993e+02,  ..., 1.09672e-02, 1.53564e-03, 2.03644e-03],\n",
       "         [4.55674e+02, 6.15568e+02, 1.11923e+02,  ..., 1.05858e-02, 1.77273e-03, 2.43880e-03]]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(next(model.parameters()).device)\n",
    "batch = torch.rand(4,3,640,480, device=device)\n",
    "print(batch.device)\n",
    "#new_model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5981ece",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.cache/torch/hub/ultralytics_yolov5_master/models/yolo.py:60: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if self.onnx_dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "\n",
    "torch.onnx.export(model,\n",
    "                 batch,\n",
    "                 \"YOLOv5s.onnx\",\n",
    "                 export_params=False,\n",
    "                 input_names=['input'],\n",
    "                 output_names=['output'],\n",
    "                 opset_version=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5c84b4a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS-DAYOLO.png\t      data\t\t\t\t\tplot_utils.py\r\n",
      "YOLOv5s.onnx\t      dataAPI.py\t\t\t\tyolov5s.pt\r\n",
      "Yolov5_Arch_w_DA.png  domain_adaptation_mnist.ipynb\r\n",
      "__pycache__\t      domain_adaptation_object_detection.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292671c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
