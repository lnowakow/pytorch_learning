{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "435499c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "bb2314b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import MNISTMDataset\n",
    "\n",
    "# Prepare Data\n",
    "image_size = 28\n",
    "batch_size = 4\n",
    "\n",
    "tf_source = transforms.Compose([\n",
    "    transforms.Resize(image_size), transforms.ToTensor(), transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "])\n",
    "tf_target = transforms.Compose([\n",
    "    transforms.Resize(image_size), transforms.ToTensor(), transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# Original MNIST dataset\n",
    "ds_source = dset.MNIST(root=root, train=True, transform=tf_source, download=True)\n",
    "dl_source = torch.utils.data.DataLoader(ds_source, batch_size)\n",
    "# Custom MNISTM dataset\n",
    "ds_target = MNISTMDataset(os.path.join(root, 'mnist_m', 'mnist_m_train'),\n",
    "                         os.path.join(root, 'mnist_m', 'mnist_m_train_labels.txt'),\n",
    "                         transform=tf_target)\n",
    "dl_target = torch.utils.data.DataLoader(ds_target, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b58cde49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 576x576 with 3 Axes>,\n",
       " array([<matplotlib.axes._subplots.AxesSubplot object at 0x7f4e9eae8e80>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f4e9eb1a700>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f4e9eaf6ee0>],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAACdCAYAAAAE7CkGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2da7AlV33dd3ef7nPOfc6dp6SRNGNLQsJIoIhHIkOEjFNxUiaBBKog2DiVOHFSrgpWsOP4AbZLVDn5ErsK25CyqeRDXCGOMbETDKrChrIKLCA2ejgQ9PJopJHmde/MfZ9nd+eDExWn12+GfVqiUkmt37dZ04/du3f3Pufsddc/qes6GGOMMWY+0v/bDTDGGGP+X8QTqDHGGNMCT6DGGGNMCzyBGmOMMS3wBGqMMca0wBOoMcYY04LOPBtneV7nvd6MVhSFbFdXlWjTyUS3C/onNEmS6IlBg63gaLxdkurnBjpvBdeB7Yv8S6CyLEWbTqdxO8OVUFNSujbclzTdl+7RdKrXUZazfVWXk1CXU+r+q9LpZHXRbQxL7N+4Tq8r3Y4PF7kd7hrZlsjtcIzxlnoOeqaoLa3PEP+cvdx/IEfnmEyq9bquj8x7rMOL/frGtdXZ4+N7ht5HKtWR2/G9jbzf+G7EDeOOxyd5mXeNPV7c88dHewn9F9GWZy6sh/XtHdx5rgk07/XCiTvvnNFOnDgh2w3390W7eP68aGWpk0cnz0TLCm1mlunLvqx1wkthUiiKnmh5rucYDkdwXm0fvhcr7e/t7W3RNi5eFK3UywhZquctoF8WeguiJZlul2e5aN3uomjjqX7wWd+4JNru7uw9H547JdvEUHQ74RW3HZ/RErivNWgVfUAZgwbbVdDpuhV/qKLj0ZAo4cMSTfB5R+8NvkzgGaD2pfDo03bRH1RhwNPEED+Bxn1opp/LXjizfTr6NN/EjWur4cH3/dCMVmT6ZSCjD6SgVaAFeFdkuZ4j6ejzWdGHI+oT2JfaFxJtC96hmvalnqdP79BmGnwAjUcYoSGF4+EHfxrLeC/hi1Pj3fKXf+LnoCX/uz1X/B9jjDHGXBFPoMYYY0wL5voJN9R1KBtrmduXL+tm8HW8k+vPUlWtP2mVpf5kmMPPoUQG56Cfw2jddgo/VQ729KfoEPSnEPppIIefEDrweWVlaVW07b09bctwIFoZ9DroZ8e60vP24Wds/PkPfjpeXtSfiZs/qU6ydmspk8k0nL+wPtsu/Gle96Wf63ENFH6CLKf0MzE0ED5y0s/JKfx8h2tscDxaK6/xZ1jdjsbiFH6epiUQ+rlyAj874zp75M+/sR6HLI37Gbs1SRKyxjIGLXXQT4HUDlpiSWCZhAcQNY++25BHgdoXdy8qGFT0DCVwbfEGAdAi14YTeB/R80xdSm2OXX9OpF+u/C7zN1BjjDGmBZ5AjTHGmBZ4AjXGGGNa4AnUGGOMacFcJqK6rkPZcFYM4G8+V1ZWRKvAkTEY7Oo5KjUt9FYPiNbtdUWbRn4eIGPM3o7+jeb2tpp5JhAisAimmrToi5bB35ktLanWDKsIIYTNnU3RBgP9O9XBQM1GdN4MXDiTXTVSEQt9/XvRpaWlmX9vk/EggiRJQ5bP3tsshb8Ioz8So79tpCFBppoOGDTQRUSmDfqbSmhKpNGG3UuqddCURH+Lp9eGbYF9yZhHpi4MIqE/aIbroNtGBqmXFhDQPFISsnT29Yd/uwuGLrrWlP42NrK9NVxqAm9m8hXhn6Dj33dGun4ScjTF7RrrLIoNCiFTW/RlgNkowWuLC6i5Ev4GaowxxrTAE6gxxhjTAk+gxhhjTAs8gRpjjDEtmC+JKEnEfLAHJqIcjAcTqMbSrODxF9tROpFut9BfFm0IBp+zZ8+KtgdJP3t7kPQDBgKC0jvKoe5bFGp8yiEVqQPagbU13berfb+9qWaoMfRpAkk5XTDSEKNyLFqWapvbkoprIa7qSADjEoaBd3RfPSeeFqFkHkp1ig1hryAVq9PRa6PwfMwRh/FJ10upQ2QYouSlKYwxqjSEHhBKkIK+ohCatiRJIoUhuG1gGIIUp+ikqMhzUJobRxaplGI0DxmLaDPaDt6DdMFokoszNPF54xKvoqs1kamNntPmvldxLvkbqDHGGNMCT6DGGGNMCzyBGmOMMS3wBGqMMca0YO5yZs1EoWZ5sxBC2AGTDi3EktEiz7VJZEBCI9BgKNql9XXRJrCYTGv2tHZcQdmrYa3nHQUoy9ZRU0XRU0NOt69JRBn0S7+/pNtBhAkZpMZjPS9pWA4Oy4vNGg3o3saQJiH0i1lzRwUl5DpgeOpAOSoy+NRgviHDRw3miaqEUmil3lcc75BY9APv/lHRTpy4RbSm4SWEEKZgmkNzFfDAp39LtMce/mPdMNZI1YHxCWY4KvNWgjuIkstSKA+2ubER18AGdQihbrSFDGcppDNRIhCl/9D7g9KeqAQd+2LAfBNjggnhCglDZMgBQxOmLEEnUI1B6pdIN1hsktOV9oYTgxaT+mUTkTHGGPOy4gnUGGOMaYEnUGOMMaYFnkCNMcaYFsxlIqqqSsw7ZG4Yb22JloCBgvaldV5KO6JSXvtgIiIKMDeUaA4Bs9FEjTaTEaUnqTbOVJtMtS0jMPNkBZh54DryXLWVFd2Xyp6RMYu2m0x12Cx0m8antrExdQiNpKMEzDxp0GtKaTtIjSGvQ5XovmUFBq8OlIbrqdbtqvb6N/0d0d507ztES8AI1gUzVwVmjI3Ll0SjVJs3f+97RDt0UMsGbl16XrT9gT6PZaX9XMCYpXKAm1taqm8fnvmqIlNJOxNRkiQhbSSmTeGZ7cD4icwICgkkY1ECGBJdtwskTPWhUn/0/YmMNiBhcBddG5ULI4NPrMkpLlEp3jQVlw52JfwN1BhjjGmBJ1BjjDGmBZ5AjTHGmBZ4AjXGGGNaMJeJKEkSMa70emAUKDWFZzxSQwaVOwqQCDMcqWGII1Liyt9QEgYl55BJg0qXfdetJ0X76C/8tGhkmirAbJLCQn4FffUDP/Uh0c5cvChaDmXUOpBstLS4KBpkSmE5q6bxiZJkYijyPFx//NpZDYwcRVfbv9hfUG1RtR70R11p/47GakrrFpoS1Vs9KdqlgRpy+is3iPaNJ58TbW9vR8+bax+sLGkS1Wioz9nKyopoJ0/eJtqJkzeJ9u//7U+Jdv7cedGm8PzQ8z0k89pQn28shdZyTF2J5vEySLKiNJwEk3TiSnmVVAoQEpbQyELut5ggnRDCPvQdla9LE31HPbSl9+x933gBTkxt0fP+yu3Xi/aWQ5CqRtdLxqfocRFrpPrW5RRf3D3yzMYYY4z5JjyBGmOMMS3wBGqMMca0wBOoMcYY04K5TERZloXlhnHh8NE13K7JxiVNSBnt7YpWQRrI4oKaIIouGUF0sXd/qAvgFKOx3FOzidqZQuhD2aaP3f8zovUgheXCJU1oOnRAr+3IQe3TcxcviDYeq1lrAKXLJhPt0xwME/RxaqHf1+NNv/V5Y0sWNen1uuHWm2fNLBUYfFJwSnRg3KUdKAMG/bG7r/22D8lMR68/Lto9f+OfaFsgEYr6cmVZjVtPP/k10f7VL7xXtMFAzUZvvOdtov3z9/8bPe+qjrE0hbFd6zg+d1FNRGS26cIzSs9tp9DzkgktAYPL+oa+V2KJSZwhIyEW7YLUshKuIYP3ByXk7MF5nxuSsQraAu17/6nLoj20DeZMeNam0JZ9KAkY25i3/+lp0X7nTjXYfe9BfTdSMhRBJeL4xoGxSIyiLmdmjDHGvKx4AjXGGGNa4AnUGGOMaYEnUGOMMaYFc5mI6roOk+lskkYJi8mrq5rCsr2thocMUmJyMH0sLS6L1utpIszy0qpoG5d08fytd79RtB9+u5ovKkyuUO0L//1h0b725J+L9pHf+l3R/um73i7aj/3Qu0T7Zx/6JdFOPXNG2wdJSXVQ088k1ftGJpwK7gelMRX57Hbj+IpAM+zu7oUvffnLs22glChIu8KkGjQOqFRBAtYUSm/dtXBMtNtf9V2idcCkdfbcM6JdXj8l2i/94o+ItrmpZpk+PD+PPvp50X7ntz8i2vf/rR8WjUw1P/6THxbt/p//e6LtbqtBbm3toGhkItrdV7PWcKgpUFSWLYT2JqLmeKHxk4IZhQwqKVbP0v5M4RnbBVPbh89qn3zgjJousUIXjGUCnxco64hGG6xxFpfQtA/38V2P6bvs1JteIdoqlPrjtDntA2wd7Js0b+ZV/JD+BmqMMca0wBOoMcYY0wJPoMYYY0wLPIEaY4wxLZjLRFRVVRg3yiUllc7BB1bUzHMZzDx7e2oEWVzW9ImFrpol+gua6kJ+kcsbG6KRQSHLdXE/C6r9l8+rSeNnf/mjolEyyQ3XqgHljltv0fMWmmJDZoGcUjm0yeQrCjUYpKbkFQCRjBB5o80JlSKKoCzLsLm5PaNR+gjdr25XjWVLS5r0s7SgpZPSjp6DEouoy7/80GdFyzM1y/zuJ39VtKefeETPCyaLQ0ePiNZf0GvrQnm8088+Kdqzzz4h2nfceLNoKRhI6lT7fjhR08bFy5uilfBcjKBcIRnHypbpVkiSyDiOPTqaUeCZYHOLXtdzI+27nz2jpsvYBqI5KLbkF21H/Y6Pd+QzD+dAAxfuqv2X0AuO2oJdAG2RMeokImOMMeZlxROoMcYY0wJPoMYYY0wLPIEaY4wxLZg7iWjcMOBsgVFg46Kmg+SQINEt1ASRJGq+6IPpo0dmiWe0TM758xdFe+gRNW78tbv/imivBoPPR//jJ0TbHeyLRgakO2/T473l7jeI9sAfPSTac2fPihYSWFDXrUKno31FfiHML8HUHhVl2b2l3yPP83DsumtmNDIJpGBkKcB8tbCgBrReT8cYJWpVQe/rmec1YeoTH9e0HgrNeeqpR6POS2YZ6s6dXTXfJOByOv2smpxe9/o3i/baO+8SrZPphWztar8Mxmq4CqBNwGw0nUK5OihdVkKpw5dC3TD5UMJQCW2jZyzDRCC9a0MYGB+7oP0ZzUsxB2HJL7gQ2g5AsyKakrQP/vH1mlrVB2Mf9TMagdD3BMlQ1Gjpgyubo/wN1BhjjGmBJ1BjjDGmBZ5AjTHGmBZ4AjXGGGNaMJeJKEmSUDTKiO3tDmS706fUzEOmjwpMMHt7mhI0Gmpi0Xik533+eTXaDMe670OP/Zloj33jcdHuvPmkaO97998V7Ud/8ZdFu7FhhAkhhHd93/eIFiZjkT79uQdFe/L0C7ovGJUyMJFMYbuyBssQGDeovBwZkMaNNJm2JqKqrsOokQBE6TUctqIloBJIwCJTAJYzI4MPmEqeeVZLMZXkIkJnA5RTogQbMqnUYHCBfek6EmhKH0qNJStq9Nva1n7e29PnkWttgQENuop2HUMyVFvqUEvaEX2boHJmfA2q0TVMYOz9BpiIMF2HUqHwOWtvBEK/DCb9EDS+VbvvxGHRPvidR0XrxpqcXkoqEiYRNZ8XJxEZY4wxLyueQI0xxpgWeAI1xhhjWuAJ1BhjjGnB3CaiZtmetAbTylRNC0WhpxqNdbvt3W3Rzp6/oI0hEwx8HqAUHlpQ/3f/7TOivfrmG0R761/V5KDD//rnRDuwtizaa27RclEff+Bzov3BVzQpqcrhOsgMk+qCN5XWyiHSo4LF8hLWzyelGrPKRtIUmV5iKKsqbO7Mmip4CR+MNuCooPQaSoiJPAWWOIvcFQ0+lIRCxhBKJ6oin4G//f3vFO2e774X9qRkK9UqeOZrOC+lCVEpvA7eS5HCkNKO2lLreMGSWvCuoMSiGu4FHY9GHhrEMAGJDDQ40kRBLxS4t2rYMIN7RuXmakqKgj54cEtNU1tg9lwBAxKNn9h3DT1/V3AjNv595WP6G6gxxhjTAk+gxhhjTAs8gRpjjDEt8ARqjDHGtGAuE1FIktDJ8hmpgnSMptEohBCqTE8FlZJCVkAizFDTevJOLhoEroQJlamCte5HHn9GtGee1fSf245rwtCbXnObaN2uXu8UjAZPndH0pDMbkJ4Dpp8SSkNRwtDSohqQkqAatY8SVnp9TafpH5zVLpzTNKoY6jqEYeO6ahhjaNMB0woaL8i0Qm0Bo0TS0fuK5gQqSUamEjARZfCsdCBhio7XLdQwdvKGm7R9QZ+f8xfUrLe7uyXagQMrovV7ejxK00ENXCB43yAtaidoKlIMSZKgOYa2izpeZNJPCuNiEe7t7iQunolMTmjwwbEHDSQDG71Y4XhoroJdv7qlZfje8rCmeb1yQd9R//XV+v7FOYjGGXxfpLmK3xmMv4EaY4wxLfAEaowxxrTAE6gxxhjTAk+gxhhjTAvmMhF1Op1w+PCRGY3Sa6jszt6+OneGU02fSFJdOO4VUGYr17k/z8G4A1E6UyiPVcKi8/3/WdOJjq31RTvcVwNFs+xbCCF87s+eEu33vvI10W669RWiZWCaIhNEnkNbCu1T2q7f12tbXFTDENIwOPzh03pdccdJQ5ovzEgduNclGEpo8Z88IPypMS5dpgLzxMqimmoOrWnJJjJ3YHUmMIylZGyAcXz33W8R7Z3v+IeiZWmckeqDP/0PRNvduiQa9UtGKT5o7qCEJozngRa2p2kQovtTQR8jZKqBzZbgmf39Ww+K9rrHLuop4Hh0DjIW1VSEMCaFJwQ0xNF2dWzSDxzvz6GMZQ5JRAmMW0rDw55BpyAlfDX7yuXMjDHGmJcVT6DGGGNMCzyBGmOMMS3wBGqMMca0YC4TUb+/EF51x2tmtF5Pk0+WlrSU1+6uJoY8f35dtEuQwlNOwGwE7VtYWNDtYNF+Asf7zuuOiXb8qBpBLp8/J9qZLb2OtYO6786+lvG5/sSNolHpKvqkQylLlJ5TdCGJCMwclDiyt6f3jbZrruNjekkEWZqG5cWl2WPXmkRV11DWCK59isYQbRsFybz+L323tq+j5339a98o2jve9l5tHxhSUkgdIhNIoLJn8BBkKTzSYO6YTrRPK4joOnZES/pRmbKy0mfq8uXzovV7alTrpHAvwYi4tqrvlbPPa1JSLJTO0wTNTLFmmcjtemCWIYMgPVNkfIolgybfe0DfoR24jOeGOlb+J2hU5i5EtnkPtvvqjo7bu1bUsIkhS1QijsxQzX6+yjjxN1BjjDGmBZ5AjTHGmBZ4AjXGGGNa4AnUGGOMacFcJqLReBxOnZ4tU3UrpOYcaqQVhRBCBUaBZUifOH9ODTmD3V3RyAh0aV33TaBUEIQThffcfYdo77z3daLtbKvJ6cFHnxTtDW+4S7QXvviIaF/84gOiySJ24LJKZCoYl9oveQalpsCoQsebgrGkWdIuhBDSRlrUPpiPYqiqKoyGO7PHhgQa8F2EGhJDyFhE/duDxKX7P/grovUbBqcQuOTbaAppVzDwyNhAY3s0VvPEBLQa2kJeluFQnz1KXvrB99ynOwOnn/26aL/9iQ+L1i3U8JGCQWowUMPd5mUo8/cSaPYVGZcwaQ3jrfQaIDQH/SirHd33r6+q8e+By3TP6H5DyhRs14cGfvJV+u5egoftC9s69u47tSnawzvaZo7fUm0HvEZ/tKFzwZ096vu48n8BEppizGUvnid6S2OMMca8iCdQY4wxpgWeQI0xxpgWeAI1xhhjWjCXiaiuazGpHDioi87Hjh8XrYJF9t2dgWjTqS5Ob1zaEC2Fxf2MjDawIHznK24S7dYbNYmo6GjK0qe++rRof/KMlnd6271qAsjASJVSKEdkDa4803N0g2pYagmSTrJctUCltWCBftJYjB+SgyKCJKlDns4aaxK413T/KcEnSXSI33XX3xTt0OHrRLuwrik3BZgiKiitVk5Ve+KJPxXt6DFNolo7qGMRS21RYhWMHSpdtwSmqTzH/BZR9nbULPKVP/mCaJc31QiUF5RWo+cYjkaind3Q90Br6lpTaCLrhcWWpauqODPPdV0doz92rd6fz1zS9yXdMTIRkfYj12jqUHGV0l3fzCK8Fw6AGYrMitQW4tquvo/uu05LB8beNzwrme7iPUT+BmqMMca0wROoMcYY0wJPoMYYY0wLPIEaY4wxLZjLRJSlaVheml3E7eR6CCrFs7ioi7+Li7qI3YXyaItQpmw6VjPHFIwblDTx2lu/Q7RbblATya///h+I9h8+r0aQO27TNKYSS/boMnYBfTWFsldkpClg0Z7cDGMoXZVBGa2iULNJCUlENfRpCO3KlzXJsjSsrsyWvCqghBiVY2MTkZ7jnnveKtrJk68WbTLR68ygBtRTTz8m2oMP/p5ot95yu2ivfOWdoh08uCZaCmXK8o5qjz72JdE+88DH9XhgrqL+S2F8UkrQl77ykLYPyuhNRtqnE0hASsFwly9oObMQNJkmlpjEmQSe2ZQMcjDQ2PhFY4rKucU5WWgrSt8i484FGN8VnPfrQ70/951Sg90XttX4hS1EiQxX1M9x/ZLAdmRWo/t7tfJlTfwN1BhjjGmBJ1BjjDGmBZ5AjTHGmBZ4AjXGGGNaMJeJKM2ysLQ8awY6fPiwbLe6piaICXhMej1IwijUREQJOdMp5UroSd54+22ive2eu/W8uRoeHnzkcdG299VAQaviWa7XAb6XQCanAOW2Ulp4z+KMOzWdFw6YF2DcgCFSQ2BRr2FA2YIycjEkIYS8YRoiQ0WN6T9qeJqC9slP/qpo/+InPyLasWM3iJaC6SDvqDloZbkv2okbbxbt8OFrRIst1fbE42pe+rWP/rxoz5zWcnvgUwvTsfZpDZ+xKd2pA2lHYaDJORO4H1QyLIOkmxpKxL0UYhJxeBttL5mDaNyy0S0usYgSpWLPS9p/Wtf7cxbGwCaU4fvqnpbco66qYaBB1bgQwDTGZp64a6Nd0RpE98NJRMYYY8y3F0+gxhhjTAs8gRpjjDEt8ARqjDHGtGAuE9G0LMPG5cszWtHTsjsZlNmitI0CUocoGCIv4HiFNn0KCSlHDqmh6eCSGjzWN7Qk2cqKpiet7evieQmmn8FAk5JGI00EKiCtpQdaDqacEgxICWy3CqWrqM1jMGFNwKxDZdm6jVSc2JJF2q4qbG7OpsvQpzwyDlB5r+lU79eljUdE+9D9/0i0X/vIp0VbAOPbwoKW77vmmmtFq8E9QQlTW9s6Ft/34+8RbX39gmob50TLMjWfUGrXYAil2tTzEwKkWGWQlFSRU4kq9YG7jnwcnXZD6oo0E3vIIFbDM0Gmp8iKWlz2DJ5jutYcxs8w0jBETMGA9IeblCYEYBoTPKkwVsilcwSMop945VE9bQVjBdpC5iUs6wgl/Kqmaeoq3elvoMYYY0wLPIEaY4wxLfAEaowxxrTAE6gxxhjTgrlMRKGuw3Qya8rogsEn76hpgQw5AcIn9sEINBhqYkYCC8cZrNBTOaYaDDS7W5uiLS2p+aa/oG0pS3VaFFBqikwFZCwKkNYyAKPBBK5jWKlpptdX40uZ6vEGJaSLgAmgt6gmrGZpLTIpxVDXtZQRw/QW+uxHBhUo+Zbm6grY3F4X7dTTXxeNDG0dMG6R0QrHLIzPn/iXamh68qn/IRrdfzovdF8owXAVwAjUX4KSgws90TqJPvNjGNuU8kL3MoNG19DmjbCjB4yghuOVseWuICUJ84rmKIvV5M2r2se/fpOe5f1QVuwixL7hMwRjj8x/PFYiHV1gfLq+r+f91C0HRHvVgj5rZMSrJpBuBQapFJ7TGva9mmlIjhm/qTHGGGP+D55AjTHGmBZ4AjXGGGNa4AnUGGOMacF85czSNCwtL89oC5Byw4YhXXQmE8QIFnWzHFJOYKF3DMdb394T7dmzF/W8W7oYvwhGGwiuCEe62r7JWA0UlAhDZaDSPK7ETgYpQaHS42U9XYw/cGhVz9FV4wKWW4OPXc3mbYOJKoYs64QDBw5e9dghcOpQBf1RwZio4ZooNednPvBe0QZDva8j0MYTNWRh6Sm0nyiU9EOGIRpPeaH3lYJaKjCa5FCWj5LGhmN9bifkEoT7RqXpUkrnSaFkWltqNfmQgYaMX2hMpFNElhqjhBzwvoV3H9R+L0t9/37gjBoxX5joOUoYBCm8azuQ+sYmQT3H7Yva5t+4Xo1pt4Gxr5xoMhaZoVKYW8gwdIUYKNi3cX+v8oj6G6gxxhjTAk+gxhhjTAs8gRpjjDEt8ARqjDHGtGBOE1EWet3ZRevFvi5i55BeMxmo0YJK0yz2lkQrp7DSC2WGprBw/Mjp06J97LOfF+2O49eIttJVs8DagWXRji6r0eI3P/ugaF9/9rxoWQYL+bBqXZHRgErEkTuk0O2WVtXoVUDC0BhMXWisaJQyOgtti6Gu6zAcz5ZUIsMQjQlKhJpCPS4yclDyDZ83zrzEZodI80mk0YS8DWQ2oi2rihJnVJtSuawExgQYhrKuvhuozSkF3UD/9Qsof/icPt8x1KEO00biF5mIKCmqjixnlkaW9KP7TeW4aJy9ew3SeqCX/3hX7xkZgagcIpnVptO4a/v7R/Sd8toFKEUJbSEDYEUl04CsA4lccC9LenbnKJvnb6DGGGNMCzyBGmOMMS3wBGqMMca0wBOoMcYY04K5TESdrBOOHjoyo/Ug5QRLTYHpo1/oAvNCT40HY0j1GU60rBgtOpeV7kvGonJlTbS1w8dE2z2v+37qG+dEu3jujGjD/W3REmjfFEr2UO03MhHVU+2DblcTXBLw+JQTbUsO58gg7aZpNEjnWYn/5jZUZdjZm02PqsHcUoFhiEw/FDWCgSRUPovMHXQKOB4ZUgIZIKi8V0IJNnRaPUcNJpC0o0aTLjx7eVe1YkFNc0VPk2R6kGJVdPW8GUVqwXhPIkuBPf7Yw1HbyfGDGpXofpPRhjQ0plEaV+RYoeeTjG7ED0JiEWnUZro9ZOiKLVdI+1JCE10ZlVsjKFEJU6CgnyswGTbfGVcrS+dvoMYYY0wLPIEaY4wxLfAEaowxxrTAE6gxxhjTgrlMRFmWhqWVWVMBmUXI9EPpHXmui8SjSkvY5Lr+HXp9NTJMhpCkMtW29HtqeFjqawJSv6OmijCBBKR9LR80HWs5qx6YKjoZlJqCRfECzFU96PvdPW1LAX0VwGw03t3VtuieuLjfLHFVwvFjaa7/k2EIF/bBoNFMSAqBy4rRUeMAAANeSURBVB9xQ+B4sG8C52DbQdy+SaKPJRkgSEtTHWPFgqZOLS0eFO3AwaOi9Ze07B2VR8vAvETP3nis43M00JKD+0PVpvBeaU2SSDINm8bIhAb3AkuXqTaFZC86byeyHCC9f2sy02HKElp3RKEyfEmkoYn7FMxLkalNBF0HtY/uEbnzxIxqE5Exxhjz8uIJ1BhjjGmBJ1BjjDGmBZ5AjTHGmBbMV84sy8LK6qyJiNJfLlzUZJ7RUA0Ao2ok2vbuZd0OTAYrS2qqKTraFlpk7y1oWaQDB9Us0aHEnQ4sdtdQEgc/m2j7BiM1TVWwkF+Ao2UIhqY9MGnsX9Z+zrah3A9YhiZjSOoAI03WSKepppTw8a2pQyLlmNh0oPuihtEvdG+gtBPcazIlcbQRlGJCDwOcF2JoUhiLdarjuAvJQUePXS/aNdfcKFqvr2ajrW01ll3auCTaaKTP6N7ulmjDgaZxjUaaKjYa7IhWwXh/STRuG6bmxHnVQh35XSQ2TYjO0Sy/FsIVys2BRtcWan3903Zk8KFSbWykijM0xZqNoq8N2kJmKLrBV0seknNHb2mMMcaYF/EEaowxxrTAE6gxxhjTAk+gxhhjTAvmMhEVRRFuuPH4jDYA08rzZ58X7eiRI6JR1Mt4rKYaSms5dlRTU9Y3zorWX9PUlOWjYEA6rCaN4UDbsjdRE8RwottRFE0n1e5OCohZgmSNXl+1AZirllb1eGmhSUQdSKzRHgihAjNMt6fXkfVmDS0b+VxD60WozFQGfUTtosSiKWgBpBQqJ6VYGkw1KolEhoVqGlceLcvAKFGoYai3oElZa/CcXXP8OtEWwWy0tanP8sULagjc21WDz2ik+w6Hut0E3hclPD/TsRrfyGz0Umh6WSg5KLbEGZnVyNxCGppbgIKMZNRmePlQOtEk8l1L5yDzKCYCYcIQ9VVsSpcerYw0LHLf63bNJCKXMzPGGGNeZjyBGmOMMS3wBGqMMca0wBOoMcYY04JkntSFJEkuhhBOf/uaY/4/4kRd1+QcuyoeY2ZOPM7Mt5srjrG5JlBjjDHG/AX+CdcYY4xpgSdQY4wxpgWeQI0xxpgWeAI1xhhjWuAJ1BhjjGmBJ1BjjDGmBZ5AjTHGmBZ4AjXGGGNa4AnUGGOMacH/Al7xs9+gGO0QAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_utils import dataset_first_n\n",
    "\n",
    "# plot first n images\n",
    "def plot_first_n(ds, n=3, cmap=None):\n",
    "    \n",
    "    max_cols = 5\n",
    "    num_rows = math.ceil(n/max_cols)\n",
    "    num_cols = n  if n < max_cols else max_cols\n",
    "    print(f'subplot will have dimensions {num_rows}, {num_cols}')\n",
    "    \n",
    "    mnist_iter = iter(ds)\n",
    "    i = 0\n",
    "    f, axarr = plt.subplots(num_rows, num_cols)\n",
    "    for mnist_data, _ in mnist_iter:\n",
    "        \n",
    "        ch, h, w = mnist_data.shape\n",
    "        if num_rows > 1:\n",
    "            axarr[math.floor(i/num_cols),i%num_cols].imshow(mnist_data.reshape(h,w,ch).squeeze(), cmap)\n",
    "        else:\n",
    "            axarr[i].imshow(mnist_data.reshape(h,w,ch).squeeze(), cmap)\n",
    "        i += 1\n",
    "        if i == n:\n",
    "            break\n",
    "    np.vectorize(lambda ax:ax.axis('off'))(axarr)\n",
    "        \n",
    "        \n",
    "    \n",
    "#plot_first_n(ds_source, n=3, cmap='gray')\n",
    "#plot_first_n(ds_target, n=3)\n",
    "\n",
    "dataset_first_n(ds_source,3,cmap='gray')\n",
    "dataset_first_n(ds_target,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b654b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient reversal\n",
    "from torch.autograd import Function\n",
    "\n",
    "# Autograd Function objects are what record operation history on tensors\n",
    "# and define formulas for the forwawrd and backprop.\n",
    "\n",
    "class GradientReversalFn(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        # Store context for backprop\n",
    "        ctx.alpha = alpha\n",
    "        \n",
    "        # Forward pass is a no-op\n",
    "        return x.view_as(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Backward pass is just to -alpha the gradient\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        \n",
    "        # Must return same number as inputs to forward()\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b9b56082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adverserial Network\n",
    "class DACNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3,64, kernel_size=5),\n",
    "            nn.BatchNorm2d(64), nn.MaxPool2d(2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64,50, kernel_size=5),\n",
    "            nn.BatchNorm2d(50), nn.Dropout(), nn.MaxPool2d(2),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.class_classifier = nn.Sequential(\n",
    "            nn.Linear(50*4*4,100), nn.BatchNorm1d(100), nn.Dropout(),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100,100), nn.BatchNorm1d(100), nn.Dropout(),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100,10),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(50*4*4, 100), nn.BatchNorm1d(100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100,2),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, grl_lambda=1.0):\n",
    "        # Handle single-channel input by expanding (repeating) the singleton dimension\n",
    "        x = x.expand(x.data.shape[0], 3, image_size, image_size)\n",
    "        \n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(-1, 50 * 4 * 4)\n",
    "        reverse_features = GradientReversalFn.apply(features, grl_lambda)\n",
    "        \n",
    "        class_pred = self.class_classifier(features)\n",
    "        domain_pred = self.domain_classifier(reverse_features)\n",
    "        return class_pred, domain_pred\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "67b4b336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source domain:  torch.Size([4, 1, 28, 28]) torch.Size([4])\n",
      "target domain:  torch.Size([4, 3, 28, 28]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-2.2502, -1.6049, -2.9520, -2.7169, -2.2033, -2.2569, -2.3603, -2.7162,\n",
       "          -1.9947, -2.7534],\n",
       "         [-2.7625, -1.5107, -3.2489, -2.2951, -1.5996, -2.2555, -2.6103, -2.4613,\n",
       "          -2.7406, -3.0710],\n",
       "         [-2.3938, -2.3861, -1.9802, -2.2778, -2.9392, -1.8185, -2.6484, -2.0961,\n",
       "          -2.3312, -2.6573],\n",
       "         [-2.2693, -1.4606, -3.1123, -3.2380, -2.3895, -2.1132, -2.3199, -3.1039,\n",
       "          -1.8089, -2.7927]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[-0.3727, -1.1676],\n",
       "         [-0.2984, -1.3547],\n",
       "         [-0.7807, -0.6126],\n",
       "         [-0.6237, -0.7678]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>))"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DACNN().cuda()\n",
    "x0_s, y0_s = next(iter(dl_source))\n",
    "x0_t, y0_t = next(iter(dl_target))\n",
    "\n",
    "print('source domain: ', x0_s.shape, y0_s.shape)\n",
    "print('target domain: ', x0_t.shape, y0_t.shape)\n",
    "x0_s = x0_s.cuda()\n",
    "x0_t = x0_t.cuda()\n",
    "model(x0_s)\n",
    "model(x0_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b059944",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "eaee1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "n_epochs = 10\n",
    "\n",
    "# Setup optimizer as usual\n",
    "model = DACNN().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "# Two losses functions this time\n",
    "loss_fn_class = torch.nn.NLLLoss()\n",
    "loss_fn_domain = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "0723a7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndl_iter = iter(dl_source)\\nfor i in range(max_batches+1):\\n    element, _ = next(dl_iter)\\n    print(f'element #{i} has shape: {element.shape}')\\n\""
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "dl_source = torch.utils.data.DataLoader(ds_source, batch_size)\n",
    "dl_target = torch.utils.data.DataLoader(ds_target, batch_size)\n",
    "\n",
    "# We'll train the same number of batches from both datasets\n",
    "max_batches = min(len(dl_source), len(dl_target)) -1\n",
    "print(max_batches)\n",
    "'''\n",
    "dl_iter = iter(dl_source)\n",
    "for i in range(max_batches+1):\n",
    "    element, _ = next(dl_iter)\n",
    "    print(f'element #{i} has shape: {element.shape}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "94cbebff",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 2.4744 s_domain_loss: 0.6903 t_domain_loss: 0.7679 grl_lambda: 0.000 \n",
      "[11/57] class_loss: 1.3743 s_domain_loss: 0.6323 t_domain_loss: 0.7157 grl_lambda: 0.044 \n",
      "[21/57] class_loss: 1.0344 s_domain_loss: 0.6136 t_domain_loss: 0.6793 grl_lambda: 0.087 \n",
      "[31/57] class_loss: 0.7911 s_domain_loss: 0.5841 t_domain_loss: 0.6442 grl_lambda: 0.131 \n",
      "[41/57] class_loss: 0.5824 s_domain_loss: 0.5685 t_domain_loss: 0.6183 grl_lambda: 0.174 \n",
      "[51/57] class_loss: 0.4281 s_domain_loss: 0.5552 t_domain_loss: 0.6061 grl_lambda: 0.216 \n",
      "Epoch 0002 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.3807 s_domain_loss: 0.5535 t_domain_loss: 0.5773 grl_lambda: 0.245 \n",
      "[11/57] class_loss: 0.3067 s_domain_loss: 0.5311 t_domain_loss: 0.5464 grl_lambda: 0.286 \n",
      "[21/57] class_loss: 0.2840 s_domain_loss: 0.5176 t_domain_loss: 0.5432 grl_lambda: 0.325 \n",
      "[31/57] class_loss: 0.2906 s_domain_loss: 0.5698 t_domain_loss: 0.5721 grl_lambda: 0.364 \n",
      "[41/57] class_loss: 0.3186 s_domain_loss: 0.5610 t_domain_loss: 0.6021 grl_lambda: 0.402 \n",
      "[51/57] class_loss: 0.2661 s_domain_loss: 0.5616 t_domain_loss: 0.5867 grl_lambda: 0.438 \n",
      "Epoch 0003 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2407 s_domain_loss: 0.5543 t_domain_loss: 0.5569 grl_lambda: 0.462 \n",
      "[11/57] class_loss: 0.2281 s_domain_loss: 0.5453 t_domain_loss: 0.5427 grl_lambda: 0.496 \n",
      "[21/57] class_loss: 0.2261 s_domain_loss: 0.5406 t_domain_loss: 0.5570 grl_lambda: 0.528 \n",
      "[31/57] class_loss: 0.2336 s_domain_loss: 0.5090 t_domain_loss: 0.5383 grl_lambda: 0.559 \n",
      "[41/57] class_loss: 0.2357 s_domain_loss: 0.5358 t_domain_loss: 0.5062 grl_lambda: 0.589 \n",
      "[51/57] class_loss: 0.2000 s_domain_loss: 0.5616 t_domain_loss: 0.5805 grl_lambda: 0.616 \n",
      "Epoch 0004 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2154 s_domain_loss: 0.6485 t_domain_loss: 0.5652 grl_lambda: 0.635 \n",
      "[11/57] class_loss: 0.2157 s_domain_loss: 0.5586 t_domain_loss: 0.6208 grl_lambda: 0.661 \n",
      "[21/57] class_loss: 0.2240 s_domain_loss: 0.6382 t_domain_loss: 0.6088 grl_lambda: 0.685 \n",
      "[31/57] class_loss: 0.2641 s_domain_loss: 0.6162 t_domain_loss: 0.6502 grl_lambda: 0.707 \n",
      "[41/57] class_loss: 0.2325 s_domain_loss: 0.6071 t_domain_loss: 0.5534 grl_lambda: 0.728 \n",
      "[51/57] class_loss: 0.2026 s_domain_loss: 0.5939 t_domain_loss: 0.6035 grl_lambda: 0.748 \n",
      "Epoch 0005 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2243 s_domain_loss: 0.6746 t_domain_loss: 0.6101 grl_lambda: 0.762 \n",
      "[11/57] class_loss: 0.1837 s_domain_loss: 0.6412 t_domain_loss: 0.6037 grl_lambda: 0.779 \n",
      "[21/57] class_loss: 0.2369 s_domain_loss: 0.5838 t_domain_loss: 0.6138 grl_lambda: 0.796 \n",
      "[31/57] class_loss: 0.2262 s_domain_loss: 0.5887 t_domain_loss: 0.5764 grl_lambda: 0.812 \n",
      "[41/57] class_loss: 0.2660 s_domain_loss: 0.5908 t_domain_loss: 0.5992 grl_lambda: 0.826 \n",
      "[51/57] class_loss: 0.2087 s_domain_loss: 0.5709 t_domain_loss: 0.5847 grl_lambda: 0.839 \n",
      "Epoch 0006 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.1991 s_domain_loss: 0.5767 t_domain_loss: 0.5536 grl_lambda: 0.848 \n",
      "[11/57] class_loss: 0.2168 s_domain_loss: 0.5967 t_domain_loss: 0.5802 grl_lambda: 0.860 \n",
      "[21/57] class_loss: 0.1861 s_domain_loss: 0.6039 t_domain_loss: 0.6084 grl_lambda: 0.871 \n",
      "[31/57] class_loss: 0.2897 s_domain_loss: 0.5603 t_domain_loss: 0.6266 grl_lambda: 0.881 \n",
      "[41/57] class_loss: 0.2528 s_domain_loss: 0.5991 t_domain_loss: 0.5417 grl_lambda: 0.891 \n",
      "[51/57] class_loss: 0.1625 s_domain_loss: 0.5197 t_domain_loss: 0.5749 grl_lambda: 0.899 \n",
      "Epoch 0007 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2287 s_domain_loss: 0.5695 t_domain_loss: 0.5005 grl_lambda: 0.905 \n",
      "[11/57] class_loss: 0.2126 s_domain_loss: 0.5796 t_domain_loss: 0.5772 grl_lambda: 0.913 \n",
      "[21/57] class_loss: 0.2430 s_domain_loss: 0.5741 t_domain_loss: 0.5221 grl_lambda: 0.920 \n",
      "[31/57] class_loss: 0.2161 s_domain_loss: 0.5801 t_domain_loss: 0.5858 grl_lambda: 0.926 \n",
      "[41/57] class_loss: 0.2606 s_domain_loss: 0.5895 t_domain_loss: 0.5375 grl_lambda: 0.932 \n",
      "[51/57] class_loss: 0.2382 s_domain_loss: 0.5821 t_domain_loss: 0.5911 grl_lambda: 0.938 \n",
      "Epoch 0008 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.1991 s_domain_loss: 0.5434 t_domain_loss: 0.5626 grl_lambda: 0.941 \n",
      "[11/57] class_loss: 0.2048 s_domain_loss: 0.6236 t_domain_loss: 0.6021 grl_lambda: 0.946 \n",
      "[21/57] class_loss: 0.2181 s_domain_loss: 0.5961 t_domain_loss: 0.5573 grl_lambda: 0.951 \n",
      "[31/57] class_loss: 0.3113 s_domain_loss: 0.5850 t_domain_loss: 0.6458 grl_lambda: 0.955 \n",
      "[41/57] class_loss: 0.3067 s_domain_loss: 0.7249 t_domain_loss: 0.5605 grl_lambda: 0.958 \n",
      "[51/57] class_loss: 0.2316 s_domain_loss: 0.6215 t_domain_loss: 0.6769 grl_lambda: 0.962 \n",
      "Epoch 0009 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2547 s_domain_loss: 0.7100 t_domain_loss: 0.6111 grl_lambda: 0.964 \n",
      "[11/57] class_loss: 0.1888 s_domain_loss: 0.6160 t_domain_loss: 0.6747 grl_lambda: 0.967 \n",
      "[21/57] class_loss: 0.2134 s_domain_loss: 0.6152 t_domain_loss: 0.6069 grl_lambda: 0.970 \n",
      "[31/57] class_loss: 0.2284 s_domain_loss: 0.5969 t_domain_loss: 0.6079 grl_lambda: 0.972 \n",
      "[41/57] class_loss: 0.2540 s_domain_loss: 0.6273 t_domain_loss: 0.5550 grl_lambda: 0.975 \n",
      "[51/57] class_loss: 0.1903 s_domain_loss: 0.5643 t_domain_loss: 0.5704 grl_lambda: 0.977 \n",
      "Epoch 0010 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2132 s_domain_loss: 0.5796 t_domain_loss: 0.5531 grl_lambda: 0.978 \n",
      "[11/57] class_loss: 0.1983 s_domain_loss: 0.6188 t_domain_loss: 0.6319 grl_lambda: 0.980 \n",
      "[21/57] class_loss: 0.2137 s_domain_loss: 0.5828 t_domain_loss: 0.5700 grl_lambda: 0.982 \n",
      "[31/57] class_loss: 0.2851 s_domain_loss: 0.5268 t_domain_loss: 0.5695 grl_lambda: 0.983 \n",
      "[41/57] class_loss: 0.2957 s_domain_loss: 0.6274 t_domain_loss: 0.5858 grl_lambda: 0.984 \n",
      "[51/57] class_loss: 0.2097 s_domain_loss: 0.5360 t_domain_loss: 0.5981 grl_lambda: 0.986 \n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch_idx in range(n_epochs):\n",
    "    print(f'Epoch {epoch_idx+1:04d} / {n_epochs:04d}', end='\\n=================\\n')\n",
    "    dl_source_iter = iter(dl_source)\n",
    "    dl_target_iter = iter(dl_target)\n",
    "    \n",
    "    for batch_idx in range(max_batches):\n",
    "        optimizer.zero_grad()\n",
    "        # Training progress and GRL Lambda\n",
    "        p = float(((batch_idx + epoch_idx * max_batches) / (n_epochs * max_batches))/2)\n",
    "        grl_lambda = 2. / (1. + np.exp(-10*p)) - 1\n",
    "        \n",
    "        # Train on source domain\n",
    "        X_s, y_s = next(dl_source_iter)\n",
    "        X_s, y_s = X_s.cuda(), y_s.cuda()\n",
    "        y_s_domain = torch.zeros(batch_size, dtype=torch.long) # generate source domain labels\n",
    "        y_s_domain = y_s_domain.cuda()\n",
    "        \n",
    "        class_pred, domain_pred = model(X_s, grl_lambda)\n",
    "        loss_s_label = loss_fn_class(class_pred, y_s)\n",
    "        loss_s_domain = loss_fn_domain(domain_pred, y_s_domain)\n",
    "        \n",
    "        # Tran on target domain\n",
    "        X_t, _ = next(dl_target_iter) # ignore target domain class labels!\n",
    "        X_t = X_t.cuda()\n",
    "        y_t_domain = torch.ones(batch_size, dtype=torch.long) # generate target domain labels\n",
    "        y_t_domain = y_t_domain.cuda()\n",
    "        \n",
    "        _, domain_pred = model(X_t, grl_lambda)\n",
    "        loss_t_domain = loss_fn_domain(domain_pred, y_t_domain)\n",
    "        \n",
    "        # Calculate total loss\n",
    "        loss = loss_t_domain + loss_s_domain + loss_s_label\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'[{batch_idx+1}/{max_batches}] '\n",
    "                  f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n",
    "                  f't_domain_loss: {loss_t_domain.item():.4f} ' f'grl_lambda: {grl_lambda:.3f} '\n",
    "                 )\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "0eeb04e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "ts_source = dset.MNIST(root=root, train=False, transform=tf_source, download=True)\n",
    "ts_target = MNISTMDataset(os.path.join(root, 'mnist_m', 'mnist_m_test'),\n",
    "                         os.path.join(root, 'mnist_m', 'mnist_m_test_labels.txt'),\n",
    "                         transform=tf_target)\n",
    "batch_size1 = 1024\n",
    "test_dl_source = torch.utils.data.DataLoader(ts_source, batch_size1)\n",
    "test_dl_target = torch.utils.data.DataLoader(ts_target, batch_size1)\n",
    "#dataset_first_n(ts_source,3,cmap='gray')\n",
    "#dataset_first_n(ts_target,3)\n",
    "max_batches1 = min(len(test_dl_source), len(test_dl_target))-1\n",
    "num_samples = max_batches1 * batch_size1\n",
    "print(num_samples)\n",
    "\n",
    "#batch1_s = next(iter(test_dl_source))\n",
    "\n",
    "#print(f'True class labels: {batch1_s[1]}')\n",
    "#test_class, test_domain = model(batch1_s[0])\n",
    "#print(f'test class prediction: {torch.argmax(test_class, dim=1)}, test domain prediction: {torch.argmax(test_domain, dim=1)}')\n",
    "\n",
    "#total_correct = (batch1_s[1] == torch.argmax(test_class, dim=1)).sum().item() \n",
    "#print(type(float(total_correct)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "8320f0dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0001 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.794921875, Domain Accuracry: 0.6015625\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.270, Domain Accuracry: 0.587\n",
      "Batch 0002 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.80078125, Domain Accuracry: 0.5537109375\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.260, Domain Accuracry: 0.599\n",
      "Batch 0003 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.8115234375, Domain Accuracry: 0.5830078125\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.271, Domain Accuracry: 0.594\n",
      "Batch 0004 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.794921875, Domain Accuracry: 0.5830078125\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.277, Domain Accuracry: 0.600\n",
      "Batch 0005 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.8115234375, Domain Accuracry: 0.5849609375\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.271, Domain Accuracry: 0.579\n",
      "Batch 0006 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.83203125, Domain Accuracry: 0.6611328125\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.298, Domain Accuracry: 0.618\n",
      "Batch 0007 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.7978515625, Domain Accuracry: 0.6923828125\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.304, Domain Accuracry: 0.603\n",
      "Batch 0008 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.7939453125, Domain Accuracry: 0.7119140625\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.297, Domain Accuracry: 0.618\n",
      "+++++++++++++++Final Source Accuracy+++++++++++++++\n",
      "Class Accurary 0.805, Domain Accuracy: 0.621\n",
      "+++++++++++++++Final Target Accuracy+++++++++++++++\n",
      "Class Accurary 0.281, Domain Accuracy: 0.600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_source_iter = iter(test_dl_source)\n",
    "test_target_iter = iter(test_dl_target)\n",
    "\n",
    "s_class_labelled_correctly = 0\n",
    "s_domain_labelled_correctly = 0\n",
    "t_class_labelled_correctly = 0\n",
    "t_domain_labelled_correctly = 0\n",
    "model.eval()\n",
    "# Evaluate training\n",
    "for batch_idx in range(max_batches1):\n",
    "    print(f'Batch {batch_idx+1:04d} / {max_batches1:04d}', end='\\n=================\\n')\n",
    "    \n",
    "    # source domain\n",
    "    X_s, y_s = next(test_source_iter)\n",
    "    X_s, y_s = X_s.cuda(), y_s.cuda()\n",
    "    y_s_domain = torch.zeros(batch_size1, dtype=torch.long) # generate source domain labels   \n",
    "    y_s_domain = y_s_domain.cuda()\n",
    "    \n",
    "    # Inference Source Domain\n",
    "    Y_s_pred, Y_s_domain_pred = model(X_s)\n",
    "    correct_class_pred = float((y_s == torch.argmax(Y_s_pred, dim=1)).sum().item())\n",
    "    correct_domain_pred = float((y_s_domain == torch.argmax(Y_s_domain_pred, dim=1)).sum().item())\n",
    "    print(\"============Source Domain Inference============\")\n",
    "    print(f'Class Accuracy: {correct_class_pred/batch_size1}, Domain Accuracry: {correct_domain_pred/batch_size1}')\n",
    "    s_class_labelled_correctly += correct_class_pred\n",
    "    s_domain_labelled_correctly += correct_domain_pred\n",
    "    correct_class_pred = 0\n",
    "    correct_domain_pred = 0\n",
    "    \n",
    "    # Target domain\n",
    "    X_t, y_t = next(test_target_iter) # ignore target domain class labels!\n",
    "    X_t, y_t = X_t.cuda(), y_t.cuda()\n",
    "    y_t_domain = torch.ones(batch_size1, dtype=torch.long) # generate target domain labels\n",
    "    y_t_domain = y_t_domain.cuda()\n",
    "    \n",
    "    # Inference Target Domain\n",
    "    Y_t_pred, Y_t_domain_pred = model(X_t)\n",
    "    correct_class_pred = float((y_t == torch.argmax(Y_t_pred, dim=1)).sum().item())\n",
    "    correct_domain_pred = float((y_t_domain == torch.argmax(Y_t_domain_pred, dim=1)).sum().item())\n",
    "    print(\"============Target Domain Inference============\")\n",
    "    print(f'Class Accuracy: {correct_class_pred/batch_size1:.3f}, Domain Accuracry: {correct_domain_pred/batch_size1:.3f}')\n",
    "    t_class_labelled_correctly += correct_class_pred\n",
    "    t_domain_labelled_correctly += correct_domain_pred\n",
    "    correct_class_pred = 0\n",
    "    correct_domain_pred = 0\n",
    "    \n",
    "print(f'+++++++++++++++Final Source Accuracy+++++++++++++++')\n",
    "print(f'Class Accurary {s_class_labelled_correctly/num_samples:.3f}, Domain Accuracy: {s_domain_labelled_correctly/num_samples:.3f}')\n",
    "print(f'+++++++++++++++Final Target Accuracy+++++++++++++++')\n",
    "print(f'Class Accurary {t_class_labelled_correctly/num_samples:.3f}, Domain Accuracy: {t_domain_labelled_correctly/num_samples:.3f}')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3490d7e6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=28, interpolation=bilinear, max_size=None, antialias=None)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "63d9a457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([4, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,1,3,3)\n",
    "print(x.shape)\n",
    "y = torch.rand(4,3,3,3)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a577af3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3, 3])\n",
      "torch.Size([4, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x3 = x.expand(x.data.shape[0], 3, 3, 3)\n",
    "print(x3.shape)\n",
    "y3 = y.expand(y.data.shape[0], 3, 3, 3)\n",
    "print(y3.shape)\n",
    "#y.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "260cd3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 28, 28])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl_target))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bb36c215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4650, 0.3285],\n",
      "        [0.2892, 0.7568],\n",
      "        [0.1109, 0.1639],\n",
      "        [0.7242, 0.3260]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6f620504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4650, 0.3285, 0.2892, 0.7568],\n",
      "        [0.1109, 0.1639, 0.7242, 0.3260]])\n"
     ]
    }
   ],
   "source": [
    "x2 = x.view(2, 4)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6be1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
