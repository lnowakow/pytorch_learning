{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "435499c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "root = './data'\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "488ad72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/workspace/pytorch_notes/domain_adaptation\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb2314b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataAPI import MNISTMDataset\n",
    "\n",
    "# Prepare Data\n",
    "image_size = 28\n",
    "batch_size = 4\n",
    "\n",
    "tf_source = transforms.Compose([\n",
    "    transforms.Resize(image_size), transforms.ToTensor(), transforms.Normalize(mean=(0.1307,), std=(0.3081,))\n",
    "])\n",
    "tf_target = transforms.Compose([\n",
    "    transforms.Resize(image_size), transforms.ToTensor(), transforms.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# Original MNIST dataset\n",
    "ds_source = dset.MNIST(root=root, train=True, transform=tf_source, download=True)\n",
    "dl_source = torch.utils.data.DataLoader(ds_source, batch_size)\n",
    "# Custom MNISTM dataset\n",
    "ds_target = MNISTMDataset(os.path.join(root, 'mnist_m', 'mnist_m_train'),\n",
    "                         os.path.join(root, 'mnist_m', 'mnist_m_train_labels.txt'),\n",
    "                         transform=tf_target)\n",
    "dl_target = torch.utils.data.DataLoader(ds_target, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b58cde49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 576x576 with 3 Axes>,\n",
       " array([<matplotlib.axes._subplots.AxesSubplot object at 0x7fcfcd6eb820>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fcfcd709cd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7fcfcd6bd1f0>],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdAAAACdCAYAAAAE7CkGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de6xl113f136c1z33MXdenvFj7Mb2OI7HJiRN4pDQBDuPCRW0qERp1aKAVEIrCqVFqtKHqlaUVqr6EFQtFSCUIAGiKFEjQgDLGFORUpM4thPn5Rhn7JnYHt+Z3LlzH+ecffajfyBLPef7mfE6+86oavX9/Dff2Xuvtdd+rHPO+t7vL2maJhhjjDFmMdL/2x0wxhhj/l/EE6gxxhjTAk+gxhhjTAs8gRpjjDEt8ARqjDHGtMATqDHGGNOCfJGNe720WVrKZrQszWDLJEpKU52/k0Q3jP1Lm7qpYV/dOYU2EuoLdLqOPF5VV3o8apf2LXVfOjcc1KD9q2voc6r7pngtdV8cq7nz2L48CePRlDp4VTq9XtMbDme08WhPtqMxCjCWdE7cf/osCfcibMXXIQ7e8/r/aRm10P4srgdxY1Du7VxomubIokcfrB9uVm48Mdci3Ou0M77e9P6BRwxfZlVVilaWU9AK0epa3wukEQl0MMt0SsgyfYayVLdr4B01nep50PF63T50ULdraPBhTJOg74fpdAL7ap/n3y2jixthsn0Zb4WFJtClpSw8+D2HZ7TV5RXYEl5a8HIbzL0oQwghz3uiTad6g8HhwqjQAaJB63a1jf5A+5LBi3ZS6A3R7XdF297bFi2Hm7Obd0S7tLmp7U7g4uMErzfOZKJ9HvR1DJbgetDE3YV9O53ZMfjkb35JtomhNxyGe9/74Iz29S9+UbbbunRZtDTTsRzAde3Qte4MtDOpHq9q9J5o4EEPDXxYghc0v2ThwwFAzxR9mKMPfTV+wIv9QNt+gufj0fnGtXHh8Uefb9OPlRtPhB/8jT+e0epUJ6iUrhl8KMtzfQf0YZJJYBLc2toQbXPjRdEuXvyWaLu7u6KN9vRdUcLnw25f7++19TXR1tcO6XbDddEKeEedf+kl0ZZXtI3Xve6kaGmqc0sJU1Zd6/yQBx2X8+eeES2U2uftuffvo//yo7rfq3284v8YY4wx5op4AjXGGGNasNBPuGmahsFwaUZbPqA/h1Ul/C5f6c80Va0/Z1SFfh3f3RuLRj9p9pb0d/TxRPct4GfYAn7+LUrtS6+/JFpI9GceOt6oHIk2HOhPh/RT6tEbbhCtgv7VjWqjkfZlb0/7MpmoVsBa47jQMV2Z+1mmgXXXGIqiCOfOzv58NRrBT2v0MxqsrdB2pMWurTBx29FPn7Qn/Qwbe7wa9qWliP1Ax6OfiWPh9Wd9h6S4XTuakIQqzP7sWsPvnBX0g5iOdbtxSj8tahvdoT7bt67dItptJ8HjUai2B56BzcvfVm1bfxLe2tSfjs9c1J8+ac2XbBoJaGmu4saFF0RbWdGl7X4Plgzhp/IOaEfgp+iNc8+JtrY0+07Osyvfd/4GaowxxrTAE6gxxhjTAk+gxhhjTAs8gRpjjDEtWMhE1IQmFPWsAaes6I974W/MwHhAf99ZgImoqGglGv54Fsw8gyX9+6zJRPs8hnbHY9gOjDaTiZqX9nZ3RKvBMjLa0b9n7A/07yybBgxXFRk34A+DYfzSRM+Xwh9qMHrt7sDfmc39fVtZqVErhqosw7c3Zv8uroQ/xsZQCjAOBAqHSOCPwNFEFBukQCrdn9AVNAzFBWQ0aHCJCyLBHuMfpMPflcK+aPChcwOnCfnNUvjbWh6r/TDfFzgH+hNVdMbEHD+EKYQclLXej2MwCDbwN6S9VE2Nee+AaEeO6HZHjhzUvkxvFm0y1nfepS39O8vNi/ou29oE89KmHu/ixldEWx7CuS2piWi4on+TemSo79A1eD2sDHV+uHD+7My/66u8y/wN1BhjjGmBJ1BjjDGmBZ5AjTHGmBZ4AjXGGGNasJCJKAStWLB5eUu26eSQ9AKL8ZOJLpRPIbGIjBGU6B8SXTgewkJ0t6cLx2QOWl7VRKDYwO0koxBqkTAUfQzj0unq+VLaUQfC6VMYqz4ssi+B4WZSqHGhX+j4zQf04/WJoKnrUM2lJNVggkqwcgwZWeIqSdQQHI+GHDLIRX4OpfskozT5mkoXUaUhakSl+249ptotUMAEjlfA+X7yc98QrYTEKqr2QdcopeuLJrHrbCICb1AGKTSYmwSB5k1QLdanhBVVUjL5aepQWkFFFWgjB/fW2qc/pscDI+HNubaxd/K7Rdt+23tEm471nXd594Joo91Lom3taJGO8+c1UekiFBEZ1Jqg1g363t/YmD3eBN6zr+JvoMYYY0wLPIEaY4wxLfAEaowxxrTAE6gxxhjTgsVMREkSsrnK6xVU9M5qKAtEBgVIItob6UIvLeSvHtC0jQoW8kcjXSQuKygDBkaG7hIsxoNBajzWMegOwGgDBh+yRWQZlOfpQFoJnFsN5qUAxiwyfTRgUqAxXV5eFq3XmzMRtS2h1YRQT2evBSbVkKEE2kwhdaimhCGMGKI0oThzVEOuOfi8ymXAwICGSUl6vFMnjor2kQe/U7Q7j+rzQ+yCiey3H/8z0Uo6XzLCAJQgRsFGOAZtaZoQ4N6eJ9LTGBqs5QWGQzCwpTBOZCLCex6arUGkEKcayhIu//bP6YY7ahQt3vBdok3u/V5tA955HUgOumF9TbS6hLKTMGdMIaGp2Faz0e7medG2t17Wdvtz40IJZ6/+1xX/xxhjjDFXxBOoMcYY0wJPoMYYY0wLPIEaY4wxLVjIRJSERE00jZplqITUoKPJN/2epgStg8GjAoNCBm0kYDZKoPRQXejidN7Rxe7dPU35eNubPiraoKfGDfZUwHl0td0pGDcmEzUqUVpL3lFj0f/8/M9EHa+B46WZansjHZft7dnybSWUY4qhCWrywfQnSA7Kcr3H0lzvTywCRwlDVFILzVF0xLjPplRCjOuP6fFOHjsk2k994H7RbjsMBg04XzqPX3j4SdEmYO6ILel2pYJwMVzvamY1mQvBwVZHJiKlZGorqZwbGIbo/iFPFpWHwxQjlW761X8kWq/QZxs8oWHv2EnVbrtXNCqlSKlaZamNNAHSwVJ9xgcDvb+HA03aWjtyk7YL59uUs6Xaznz8Y9qPV7tzxf8xxhhjzBXxBGqMMca0wBOoMcYY0wJPoMYYY0wLFjIRpVkahsuzJb7Gu2pGmUAyD/h7sKxUCkk/ARb3KZWDTAB7UKaMDBR33f7Dot147B2irQx1IXowWFGtq+aVihJH0Bmg51ZiJIqyuakpMaHWcV4e9kUrwPhTgKGpKLQveXeujdaOjyQkc6WSEjDV0L1DCU5k+iFTUkoFn3Df2POCclywL5mIBvNjGTiN6+ialts7cVhTomoomEXXegqGma+c3dDj0fOIBj6RQhKZJoTlzK6piahB805b0GwE75kUDDRkNkIokYvu5Vrfv0d/8SdFG372t6AR7d/2qQdEO//BfypaRYYmjkpSyDNFu8KYksmJqh2S8TRP9BlKe7PvxtRJRMYYY8y1xROoMcYY0wJPoMYYY0wLPIEaY4wxLVjIRDSdluH8y6/MaF1YmM2ghE3dqBmlgXQVSvAhA01T6Apzr6/GGDG3hBBKWHVuYGV7ZeWYaN1c2+h09XhFtava9NuiDZY0jWm8p2WGxhPVaFx2R1qeh8JAtja13A8xpXQW2K6cS1ghU0UMSaIGkk5X00c6vYFoaarGLTIb1ZhsBPcEnAKlvFzrhJx//+H3i3b8gJqDwDOFpqQtuJ9+CRKGHnv2W6KNppo6FG8YAm0fg7WffWPA5KDorxiUCBT3DNA9xaakOAPSzb/2T0Q7BIahFPpcHNeEoRd/+te1L119/mLPg4k7N74ecB5TKAkIxtMcnFn1/LvsKqfgb6DGGGNMCzyBGmOMMS3wBGqMMca0wBOoMcYY04KFTER1XYe93dnyL0lfDR4ZLNYWIzUjQLWo0OurESSHRdxJqWkb411oA6wMNbhqzr74qGg33/hO0W44ekq0HTBpbFz4vGiPPf7PRcvA0NKF0mqwGZYM24ESbGurmpRETKHU0u4IzEtgLClbmoaEJJHScvlAjVYdMDGkUOKsps+IYF4jjQw5ZESILdGVggnmjuMHRTsw1HNbgrJ3IVET2YVtNa99/NEvi/boV1+AHu6n1Fjc+MUmNNFYLfSyeg2aJoSyfO10L77ecexnXz6ejnFv45ui9c+rRoahkOuI7t75FtHIMBQLjUFs8hKlLFF6FJkC8w6YByOT4NL59y+9fF/d9or/Y4wxxpgr4gnUGGOMaYEnUGOMMaYFnkCNMcaYFiy0Lp8lSRh255J4wMzTH6rpYwRlxTIwbqBZghIpwEBBC8wJfEZYXrtLtDvv/HHdNzsh2ua2JvhsnP9D3W7zGdHSOq4MFJmIpmAYGu9pX7pQDi5NYKEc0qJo4X1lRQ0EOztqVLp46dLMv9vaJ9I0Db25UmtJrsYy6n+WgIkIDQBxnxsp+IbMLbGcOnFUtL/3PjVtHF6OS3mhvnzhuVdEe+TpM9oZKKuFyUFohAEjEBlDwFgWW+IMy5lBT643bRO1Qog30HDCkO7bO/+caDf95r8QbeVLj0S1sfWWvyLauR/6t6IRdDwC04RizUGkoRGITIHUP9pXKYrZOa25Stk7fwM1xhhjWuAJ1BhjjGmBJ1BjjDGmBZ5AjTHGmBYsZCLqdDrhpmOzRohpocknS8tD0fpjiB1CVwAYbaCb62uarkOGHDJa3Hj8tGirK/eJNtpT49PW1qOivXTuV0UrSi3fNlzS1KY8pwV1HYNBT8cvCXFmk+lUTT/1lEpSxWmTQs9tqTdr4GmdwpIkIevMjlOSqYkogTJ6ZGRJKXUIPjdWkMJDRpYa03VUe+Otahj6yINvEu3Ww6t6NGhje6xmvU9/4VnR/uwVLZmXZHo8tMZQIhA8U7Hg9SAXEZWIo+NdYxdRzD1KJpiYBKPF+qFtdF6KMwytPfF7dECRtr77Q6K99Nf/lWg1lA7cz7csNBuR3yzSlMQ7R20VyshycLkYFK98n/gbqDHGGNMCT6DGGGNMCzyBGmOMMS3wBGqMMca0YDETUZ6Fo0fWZrTL21B2qAcpMbluV1ZqlikqNahUlZbP6nXUWFKVut3S8F7Ruqlq/U5fNSjj89w3NXUo74ElAwwKWaYL9EtL2sZopOYlKl0GwUGh19cUqCmYHhpKf8n0gJORmlfSPqUYzV6PrLX5JAlhriwZGYbQCEQGH9LAE5BFlliqIE2KEoY+8p43i3b7kXXon0qTSq/XLz38hGiPfPV50dBog+k/oCVgNkLTFOxLjwAZNKCGYZ3qzjkccB9+ptbEm1uu7fG6kDpEhqHY4128/4OiVauHdMNrfL7EfsY0hQStFB4i2i6HVCnuy/x70CYiY4wx5priCdQYY4xpgSdQY4wxpgWeQI0xxpgWLGQiapo6TKtZg0sNi7VjKHGWZFQbSqU+mGBG47FoNfhK0qDlx46v/5hoq0t3iDbeVuPOhd3fEG1rT40bfUgJyqEE16TQcZkU2m7eiTPITKY6LllXL2kFqUgUppJ34DxonMEgVRazfYk1n8yTJElIsjmTEpYkiz2gSg2YDqhqVdPEJc6cOKSpWHccVYNG7Jj8l4c+J9qjX4s1DMUlJZFhiJKXCCo/RoYhMnAlUIYQHp+QYXDZtU0Ami9V1jo9a5/7djZfFO34J/61aLHmm43Tf0e03ROatBabqFTXcdvFjkFsiTg+nvYlpSgirGYG9ygaFOPxN1BjjDGmBZ5AjTHGmBZ4AjXGGGNa4AnUGGOMacFiJqLQhOmcIaWAZJa0o0k1U0gY2tnZEa3X07SeutJF5/FUj7c2WBbtyIFTok0matwZ76o2aP6SaPfepqXQppCUlIAhp4HzmEzUCLRTfFq03Vf+QDRyyKRgDhn0Ne1oPIGEIVhQJ+NLAmaGZm7Bfz+Vp6iEmrRHDVDoEKbw6IYVug50uy6YZbrgeKFxI20CRo5vbmyJ1s/1USXfzltvv1m0H7z/HtE+8bmnRfvjr58RjeweNPQ5lpLT7VIo1UcmkC75PdJrayLS40NpwWueRASpOWMtCTk486RuF5mWNTr2etGKpTXdMLK8VzRgkkzBwBibdlQvaak/KneJ50HfDUmiUmhzY0Dvi6sc0hhjjDGvhSdQY4wxpgWeQI0xxpgWeAI1xhhjWrCQiaisynBpa3NGuzTWReJsPkkmBHRzTKGc2c6ummrIWDSZ6oL16kAXew8fOijaGMqFpdC/stISZwfW9HijkfZ5dVUX7aew2L19GQwjxY+KduuxnxDtT5/+YdHK+rxoPSovB+aVCkqmNWB6yMEklsxFFsWm2iiJJJCA9yqEhowIcakidK25VpY2fN/NR0T70Qe+M6pd4t995rOi/cT73iTa8TU1yCVgXqKybJ1UH/Mfe9f9ol0CI93T39oQLSfzGtzbXai3l0O6DAXOdDIyDIEh5RpChqHY1Jz9tatarJmnXNHEq3pZk7Fij7efNKGjD/1X0W74nZ+LO14PSkf+5K+LVq5oScDp2g2ipWS6QxcRnW+8cczfQI0xxpgWeAI1xhhjWuAJ1BhjjGmBJ1BjjDGmBQuZiELQYjJYUQk1UEtdrKV9y0LNAw2svBcTMDRBPa7BipZM6y2pUWk02hPt29tPiVY1aiJq9iD9B5I68kZNKYcP/gXROj0tj9bpqLa7p+NC5eDILFDB6Cew3QTGeT49qG05s5A0IZmLsElqihOi8lkgwa4V+oXi+pvBeORoQIrjlkNqNlsd6L0z6Oq1xigigE6NStdlYK7KwKyVgXmpA2OQQWpMBgaNNOhzQfsePUrJNC1pmhCK2TbYeBJH7HZoGCLzUh6XirR13wOi7d32ZtFyaHf4nJbNSwt951Gnx2DcCYW+Z0KhaXNECtvd8bPvFW104jtEO/vhnxetOqHpW1S+raZ0q7nBovKHr+JvoMYYY0wLPIEaY4wxLfAEaowxxrTAE6gxxhjTgoVMREmShs5cKtCBVM0N2ztanodSeOpSy4CN9nQxudPVRKCt7W3t3/QZ0f70aU3HyMCA0u1qug4tOn/5uf8s2mR6QbQKTBC9JTWH3H3L3xXtyJGfEq1utC9FEZcctDvS65FCOk1TUXkjNYxc37JPSWjmzEycotI+MYUMaLGQqQoNU1BWjvihd6gpAoOXwMxTo/FJ+1c3ceXWKMUopdQh0HIwB+VQK6oHpo1l9fSFkydPiPbO+98o2qc+/ru6cyT7Kt01x74Si+B25FQk1dYf+4TuDO+33TveLtrRT/0b0brbmjxF43Tx/g+JtnnqPap919/U/gHrT31G2x1pStvwnJo4j/zBL4p27sP/QbQSn3safO4j4W+gxhhjTAs8gRpjjDEt8ARqjDHGtMATqDHGGNOCBZOImhDmzCxDMMZQqSkywdRBzUF5Dgk5pS7QLw80Oagozoj22JMfhb6IhFVtelC2K810yHoDNVJN1B8VVnp3iHZgWUtXjQstK1VM1TCENppILwOVGyvBRESGhKbSazlv/GkbRBSaEOr6tT/Xkf8DjRzk76HjxZZfI4MB7QsamoPiWg30WTeBQa4SvT9pPJ8487xor4AxL4XUoS6k5OSJpgl1IWFota/He/c77hXt9Om3ibbUuXalxZIkaW0i2o9hjvZMV7Uk2dbbPyja2p/8VlQb6/9LtyMtlvEhNXRtv/G0aveoiWj7O3Q7Gr+VM4+L1gUT0ejQbaJt3aftogkLTG10D2jZsyu/G/wN1BhjjGmBJ1BjjDGmBZ5AjTHGmBZ4AjXGGGNasJCJqAlNqMOsO6bXX4ENofQSmCqKqTptur112FXn+SmYaqalltnq99Wo1IUyYKNdNe7UNST9UGko6N/yyutFe91N/0C3W9Z0lVEBDiRYxy5GatKoKt2XEpUoiYiSbWq4RmWp45Lns2PavpyZllqrwLQUYzS6EmQYooQhBl1EotD5xyYH0eda2rWBMWjgXnzizFnR/tufaCmrVy5DChg8K2mqz8qhVb0nOkHvndffeVy00+9/l2hvgCSi55/9smhtaUKArDAFDUNYkwyMVZTYBbdtsaYl7S6+9a+KdghSh2ooCZmCyUuNMSHUuV7bc3/tn4k2BuPO9j3fIxqx/pial1aefUw0SkAqoWTa2Q/9rGhbd79bNHo7xJrG9Jq7nJkxxhhzTfEEaowxxrTAE6gxxhjTAk+gxhhjTAsWK2cWQsiyWdNDWatRoIaSRVR6K6WyYh1NKqkgYWbYu1G0Ww7+tB6vqwvlF7d/X7RXKi2LlMLwJKkmIN1+4mdE63QOi7ayco9oFSxQL4Hx6Zln/6NodXVRNDJINY2aq8jUleQw9mAYyjo6LtNqdrtmgYyduR1DXc/2jUxk80ajK1LvxzBExO1LSU+0J5qDQGwa2LsBYwikgL2woeX2Ni5dEq3b0+St0KhR7cQtanr58R/5ftE6tZbRK6Z7ot104wHRMiij1++AYbElTdNcobxVBPC1g/wpJRjOuE19xrZuulu08w/8bdGOP/zL0L24coMpmCTXvviQaCtwvBv+6FdEI4Nd78VviNbdekl37Wmi3Zm/9Z9E2z4F5qXYimTx4gxX80P6G6gxxhjTAk+gxhhjTAs8gRpjjDEt8ARqjDHGtGAxE1GShO5cia/xSFNJqlpNRGTmIV9ESCDBBdI2BgM1FKwO36ptwArwoeHNoq0NtHwQJVBkkN7RH9yiu8K5UUm3NIGyO1AGam/v66JNCi33k6S6GE9JPnRuUzAMVZBiRIvqapppW3oqCc2c8SfDBJFrV9rqz5uNM5R85UVNTPnY/3hStA+9XUt0oTkI2pg//xA4/CYJarT5/LNnRPvDL31VtCzVljvJWLQU0oQGuRrpjh3V5/HowSOijbbVvLTU19fQZKzvlfUDasxrSxJCyCMuOaXXYDhRpGGIzDzwSglhTcfu5dP/EPqnY3fos78GB1To3AZnnhAN+5zHTR20b9kbivbcj/yCaFsn36EHhLkg9msgG6le+3BUNnDBpo0xxhjzf+IJ1BhjjGmBJ1BjjDGmBZ5AjTHGmBYsZCLK8zwcPHBwRqPElelUk29Ge5pKQqaKJNPj9YdqWsgz2LejiSv1VPft94+JluZaZomhlBg1Wowm50Tb2dbtti7/jmjbu5qUlMH50rhgGkhPzSYJmA+yTD9PFYVeywoW3itIwLlWVHSfQDoVApulsG+iQ4T353ii1/BTn/uKaL/75Ne0XTCWJZxPpNvBc5ZD2aoGjGpZQuXg9Hm87SZN9/qLbzwl2sbLz4r2yEN6z37gve8U7djRg6IlJTw/IzU0vXz2vGjXkthyV7gv3P5kUqrBfAOXEQNySjBOvvABTV978fTfh8PBg0B9hvcvleGLHSl+K0AbnSVtI/Z60DhjWhSVeYuNMWL8DdQYY4xpgSdQY4wxpgWeQI0xxpgWeAI1xhhjWrCQiSg0ITTzDhIwnqRgeMhg8ZxKFpFxg5hMXhDtqWd/QLTV4dtFO7z6N0SrdjWFhyJ30lzPLc22tS9f+8eidXsaOVJM1KRDRpA+xJVMpppYhAv04Prp93XRPoNSct0MrhEk5TRzDpkU7osYmtCEei6NKvZI0SXOwCVQVXH3XQfOi0xO40KNMfBYoDkopQQsMEBUFTx7md5PSa73ycpQ23jgXW8W7fsefJ9ojzz8GdHWV7UU2utuuV20LIdxhqSs3pKW9Dv7zTO6b1uaJgQp5xUdaaNSZLOYfgTVBjE1h0w1XR0naqKutRFMWSINEsqwZBp0j8eFxpkMPpHHo6Sk+LcGtBHvIvI3UGOMMaYFnkCNMcaYFngCNcYYY1rgCdQYY4xpwUImorquw97u3oxWykL8FfYFo0Vdq7khB9NKCmYjMqlkmZ7OqHhctLMXVMugXYJMTkWhi84J9Lksdd/h8rJodaVjSu12octkGEp6alTpdOMufTXVdksocdXNZ80MsXYeIpkz0SRQ4o4MQ2TIiTWlxRqQqI35/oYQQg0l/WjfkMBnWEh1SsDckUD8TZ5ru6fuulW0u27XNK5irGa4hx7+tGhrfTUMvfnUG0Srx3uipV0wSMFzW8G74fhxLfHVmiQRE01s8g2W98KyZ3HlzGLbwCQd6nNkG9HsY1xi9409HhqkQEWbUuQ1WiSKyN9AjTHGmBZ4AjXGGGNa4AnUGGOMaYEnUGOMMaYFC5mImqYJ5VzpoUuXt2Q7MrIMloaibW3pvoOlgWjDoe5bj6FsF+xLbpaiUINCMVVjDCURkZkjTTUlqDdQbTzSdslD0snUpFHX2r/pFIwlYGjp9zWthBfU1YDSTFVLoeRRPpdiRH6ZGJJES4ulcBHRkLMPog0kYPCB4biCKY2MIboVeKbQMNSkek/0umpAe9tb7hbt+//y+0X7zH//pGg725uivf9dp0W7cV2TrZJE+5LADU8hUA3cx+uHD+uG15lYM08OSWuxJpj9EGuMie5f5L7Yl0jzUgqlFON9T3HPEHurwPCKj/1cG1d51fgbqDHGGNMCT6DGGGNMCzyBGmOMMS3wBGqMMca0YCETUZImYkg5BIYXWnWlhehuV40201JNKzm0UQZKQNJ2ux1tg0pD1WBamIKxiMwhHShTtpSq8Wm3syMaLXZT/3Z3wTDS74lGJa66PR0/OjfK7MnhGnWgtFpnbjsyW8Uy7zNJmvYJQ7FmowZcDLRrDaW3Qqp9oUQt7AkYt6jMX2j0eg2Hel3vvuMW0dZXNe3qqS88KdrmxUuifd/3vlu0Y0fXRKvGagjMO9q/NIBBbt41FkLIMjDhTUai7Yf5Kx5rqiHjTkkumFgTUayBjQw0ZaT7Btug843ZaoFya1Gt7s9whaXVcFxIA1Po/GZXedX4G6gxxhjTAk+gxhhjTAs8gRpjjDEt8ARqjDHGtGAxE1FIQmcuRSLp6CHIoEIWivW1g7pvqfumUO5oAmlCFaTEFIUej9JQBkNN6+l21eBRgemjk5OxiMqyaRtFUYg2Ho2hXTVN9QcropVTHQO6Hnt7asioIBKm01GjElSSC6G+NtQ4nIYAAAJASURBVJ/FmiaEes5IRuXs6jrORJRBTBAZkBI4XpLrOQ2HmnZVgbGoKvX+pL6QQQH7DEal5aE+FyfvvF23W1oV7anHtaTf8UOa9HP8qD6jYzAMDejU4H6q4eZJM30u6gbKFfb0PFrTNGJciTXBxJfFitu3jHx0YtN6qLQaGoZoZ0rwwX3bZyrFngcblXS72DdPdLW1edFJRMYYY8y1xROoMcYY0wJPoMYYY0wLPIEaY4wxLVisnFndhNF41hxRgoGi14OyYmCWmEzUaDECLYdUkizXld3JRA05bDZRrazUaEPnNhqrwSeF+lO9PhhQljURhvpCCTgrK5psVE7VWLS9vStaDkagstR2Kdzn0qVt0QZ9bXcvmx37KjYhZY4k4RJvMWToboojhX2Xh3q93nDPXaJ945lviHbpkt4n5EbIUjAMBSgrB+a1VTC+rULq0OUdvSdGYFS795SWPVvq6SsiqdSA1kBJvyTX/tErpyj0xsvgHZLlccaxKJIQ0lyyiGBDcp7QAcloQ4lnsOc+TDXkgiFTEpUaizU+RfcldjswHFKJMzZ1tU+Liu3ffGre1bLM/A3UGGOMaYEnUGOMMaYFnkCNMcaYFngCNcYYY1qQxJaFCiGEJEk2QgjPX7/umP+PuLVpmiOL7uR7zCyI7zNzvbniPbbQBGqMMcaYP8c/4RpjjDEt8ARqjDHGtMATqDHGGNMCT6DGGGNMCzyBGmOMMS3wBGqMMca0wBOoMcYY0wJPoMYYY0wLPIEaY4wxLfjfvwCSjHgZV40AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_utils import dataset_first_n\n",
    "\n",
    "# plot first n images\n",
    "def plot_first_n(ds, n=3, cmap=None):\n",
    "    \n",
    "    max_cols = 5\n",
    "    num_rows = math.ceil(n/max_cols)\n",
    "    num_cols = n  if n < max_cols else max_cols\n",
    "    print(f'subplot will have dimensions {num_rows}, {num_cols}')\n",
    "    \n",
    "    mnist_iter = iter(ds)\n",
    "    i = 0\n",
    "    f, axarr = plt.subplots(num_rows, num_cols)\n",
    "    for mnist_data, _ in mnist_iter:\n",
    "        \n",
    "        ch, h, w = mnist_data.shape\n",
    "        if num_rows > 1:\n",
    "            axarr[math.floor(i/num_cols),i%num_cols].imshow(mnist_data.reshape(h,w,ch).squeeze(), cmap)\n",
    "        else:\n",
    "            axarr[i].imshow(mnist_data.reshape(h,w,ch).squeeze(), cmap)\n",
    "        i += 1\n",
    "        if i == n:\n",
    "            break\n",
    "    np.vectorize(lambda ax:ax.axis('off'))(axarr)\n",
    "        \n",
    "        \n",
    "    \n",
    "#plot_first_n(ds_source, n=3, cmap='gray')\n",
    "#plot_first_n(ds_target, n=3)\n",
    "\n",
    "dataset_first_n(ds_source,3,cmap='gray')\n",
    "dataset_first_n(ds_target,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b654b80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient reversal\n",
    "from torch.autograd import Function\n",
    "\n",
    "# Autograd Function objects are what record operation history on tensors\n",
    "# and define formulas for the forwawrd and backprop.\n",
    "\n",
    "class GradientReversalFn(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        # Store context for backprop\n",
    "        ctx.alpha = alpha\n",
    "        \n",
    "        # Forward pass is a no-op\n",
    "        return x.view_as(x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # Backward pass is just to -alpha the gradient\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "        \n",
    "        # Must return same number as inputs to forward()\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9b56082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adverserial Network\n",
    "class DACNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3,64, kernel_size=5),\n",
    "            nn.BatchNorm2d(64), nn.MaxPool2d(2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64,50, kernel_size=5),\n",
    "            nn.BatchNorm2d(50), nn.Dropout(), nn.MaxPool2d(2),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.class_classifier = nn.Sequential(\n",
    "            nn.Linear(50*4*4,100), nn.BatchNorm1d(100), nn.Dropout(),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100,100), nn.BatchNorm1d(100), nn.Dropout(),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100,10),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(50*4*4, 100), nn.BatchNorm1d(100),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(100,2),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, grl_lambda=1.0):\n",
    "        # Handle single-channel input by expanding (repeating) the singleton dimension\n",
    "        x = x.expand(x.data.shape[0], 3, image_size, image_size)\n",
    "        \n",
    "        features = self.feature_extractor(x)\n",
    "        features = features.view(-1, 50 * 4 * 4)\n",
    "        reverse_features = GradientReversalFn.apply(features, grl_lambda)\n",
    "        \n",
    "        class_pred = self.class_classifier(features)\n",
    "        domain_pred = self.domain_classifier(reverse_features)\n",
    "        return class_pred, domain_pred\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67b4b336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source domain:  torch.Size([4, 1, 28, 28]) torch.Size([4])\n",
      "target domain:  torch.Size([4, 3, 28, 28]) torch.Size([4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-3.2312, -2.7003, -1.8831, -1.7526, -1.6379, -3.3733, -2.5863, -2.6556,\n",
       "          -1.8112, -3.5002],\n",
       "         [-2.6910, -2.6012, -1.6860, -2.0630, -2.5157, -3.2207, -2.7131, -1.2961,\n",
       "          -2.6798, -4.1090],\n",
       "         [-1.6913, -2.4938, -2.9626, -1.8189, -2.9650, -2.8794, -1.7845, -2.0585,\n",
       "          -2.3709, -3.7904],\n",
       "         [-2.9101, -2.9688, -2.2144, -2.1910, -1.4943, -3.5876, -2.6090, -1.9724,\n",
       "          -1.7049, -3.6288]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>),\n",
       " tensor([[-0.7226, -0.6646],\n",
       "         [-1.0556, -0.4277],\n",
       "         [-0.4652, -0.9889],\n",
       "         [-0.5888, -0.8097]], device='cuda:0', grad_fn=<LogSoftmaxBackward0>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DACNN().cuda()\n",
    "x0_s, y0_s = next(iter(dl_source))\n",
    "x0_t, y0_t = next(iter(dl_target))\n",
    "\n",
    "print('source domain: ', x0_s.shape, y0_s.shape)\n",
    "print('target domain: ', x0_t.shape, y0_t.shape)\n",
    "x0_s = x0_s.cuda()\n",
    "x0_t = x0_t.cuda()\n",
    "model(x0_s)\n",
    "model(x0_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b059944",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaee1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "n_epochs = 10\n",
    "\n",
    "# Setup optimizer as usual\n",
    "model = DACNN().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "# Two losses functions this time\n",
    "loss_fn_class = torch.nn.NLLLoss()\n",
    "loss_fn_domain = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0723a7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndl_iter = iter(dl_source)\\nfor i in range(max_batches+1):\\n    element, _ = next(dl_iter)\\n    print(f'element #{i} has shape: {element.shape}')\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "dl_source = torch.utils.data.DataLoader(ds_source, batch_size)\n",
    "dl_target = torch.utils.data.DataLoader(ds_target, batch_size)\n",
    "\n",
    "# We'll train the same number of batches from both datasets\n",
    "max_batches = min(len(dl_source), len(dl_target)) -1\n",
    "print(max_batches)\n",
    "'''\n",
    "dl_iter = iter(dl_source)\n",
    "for i in range(max_batches+1):\n",
    "    element, _ = next(dl_iter)\n",
    "    print(f'element #{i} has shape: {element.shape}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94cbebff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0001 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 2.4584 s_domain_loss: 0.7831 t_domain_loss: 0.6756 grl_lambda: 0.000 \n",
      "[11/57] class_loss: 1.2835 s_domain_loss: 0.6335 t_domain_loss: 0.7096 grl_lambda: 0.044 \n",
      "[21/57] class_loss: 0.9343 s_domain_loss: 0.6033 t_domain_loss: 0.6848 grl_lambda: 0.087 \n",
      "[31/57] class_loss: 0.7330 s_domain_loss: 0.5849 t_domain_loss: 0.6470 grl_lambda: 0.131 \n",
      "[41/57] class_loss: 0.5529 s_domain_loss: 0.5661 t_domain_loss: 0.6244 grl_lambda: 0.174 \n",
      "[51/57] class_loss: 0.4123 s_domain_loss: 0.5459 t_domain_loss: 0.6309 grl_lambda: 0.216 \n",
      "Epoch 0002 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.3515 s_domain_loss: 0.5693 t_domain_loss: 0.5668 grl_lambda: 0.245 \n",
      "[11/57] class_loss: 0.2831 s_domain_loss: 0.4974 t_domain_loss: 0.5296 grl_lambda: 0.286 \n",
      "[21/57] class_loss: 0.2909 s_domain_loss: 0.5594 t_domain_loss: 0.5740 grl_lambda: 0.325 \n",
      "[31/57] class_loss: 0.2896 s_domain_loss: 0.5134 t_domain_loss: 0.5782 grl_lambda: 0.364 \n",
      "[41/57] class_loss: 0.2657 s_domain_loss: 0.5624 t_domain_loss: 0.5116 grl_lambda: 0.402 \n",
      "[51/57] class_loss: 0.2387 s_domain_loss: 0.5259 t_domain_loss: 0.6039 grl_lambda: 0.438 \n",
      "Epoch 0003 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2373 s_domain_loss: 0.5620 t_domain_loss: 0.5648 grl_lambda: 0.462 \n",
      "[11/57] class_loss: 0.2136 s_domain_loss: 0.4990 t_domain_loss: 0.5280 grl_lambda: 0.496 \n",
      "[21/57] class_loss: 0.2375 s_domain_loss: 0.5702 t_domain_loss: 0.5548 grl_lambda: 0.528 \n",
      "[31/57] class_loss: 0.2731 s_domain_loss: 0.5927 t_domain_loss: 0.6322 grl_lambda: 0.559 \n",
      "[41/57] class_loss: 0.2681 s_domain_loss: 0.5853 t_domain_loss: 0.5506 grl_lambda: 0.589 \n",
      "[51/57] class_loss: 0.2164 s_domain_loss: 0.5054 t_domain_loss: 0.5583 grl_lambda: 0.616 \n",
      "Epoch 0004 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2316 s_domain_loss: 0.6300 t_domain_loss: 0.5466 grl_lambda: 0.635 \n",
      "[11/57] class_loss: 0.2235 s_domain_loss: 0.5827 t_domain_loss: 0.6535 grl_lambda: 0.661 \n",
      "[21/57] class_loss: 0.2252 s_domain_loss: 0.6224 t_domain_loss: 0.5519 grl_lambda: 0.685 \n",
      "[31/57] class_loss: 0.2257 s_domain_loss: 0.6039 t_domain_loss: 0.6187 grl_lambda: 0.707 \n",
      "[41/57] class_loss: 0.2825 s_domain_loss: 0.6271 t_domain_loss: 0.5973 grl_lambda: 0.728 \n",
      "[51/57] class_loss: 0.2270 s_domain_loss: 0.5924 t_domain_loss: 0.5808 grl_lambda: 0.748 \n",
      "Epoch 0005 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2153 s_domain_loss: 0.6358 t_domain_loss: 0.5422 grl_lambda: 0.762 \n",
      "[11/57] class_loss: 0.1960 s_domain_loss: 0.5610 t_domain_loss: 0.5680 grl_lambda: 0.779 \n",
      "[21/57] class_loss: 0.1960 s_domain_loss: 0.5634 t_domain_loss: 0.5445 grl_lambda: 0.796 \n",
      "[31/57] class_loss: 0.2649 s_domain_loss: 0.5756 t_domain_loss: 0.5677 grl_lambda: 0.812 \n",
      "[41/57] class_loss: 0.2493 s_domain_loss: 0.6263 t_domain_loss: 0.5262 grl_lambda: 0.826 \n",
      "[51/57] class_loss: 0.1983 s_domain_loss: 0.5050 t_domain_loss: 0.5218 grl_lambda: 0.839 \n",
      "Epoch 0006 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2041 s_domain_loss: 0.4933 t_domain_loss: 0.5005 grl_lambda: 0.848 \n",
      "[11/57] class_loss: 0.1824 s_domain_loss: 0.5170 t_domain_loss: 0.5140 grl_lambda: 0.860 \n",
      "[21/57] class_loss: 0.1880 s_domain_loss: 0.4754 t_domain_loss: 0.4924 grl_lambda: 0.871 \n",
      "[31/57] class_loss: 0.2178 s_domain_loss: 0.5307 t_domain_loss: 0.5156 grl_lambda: 0.881 \n",
      "[41/57] class_loss: 0.2830 s_domain_loss: 0.5223 t_domain_loss: 0.5596 grl_lambda: 0.891 \n",
      "[51/57] class_loss: 0.2517 s_domain_loss: 0.5282 t_domain_loss: 0.5079 grl_lambda: 0.899 \n",
      "Epoch 0007 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2237 s_domain_loss: 0.5262 t_domain_loss: 0.5808 grl_lambda: 0.905 \n",
      "[11/57] class_loss: 0.2163 s_domain_loss: 0.5836 t_domain_loss: 0.6012 grl_lambda: 0.913 \n",
      "[21/57] class_loss: 0.2133 s_domain_loss: 0.6666 t_domain_loss: 0.6031 grl_lambda: 0.920 \n",
      "[31/57] class_loss: 0.2710 s_domain_loss: 0.6717 t_domain_loss: 0.6628 grl_lambda: 0.926 \n",
      "[41/57] class_loss: 0.3204 s_domain_loss: 0.7039 t_domain_loss: 0.6442 grl_lambda: 0.932 \n",
      "[51/57] class_loss: 0.2279 s_domain_loss: 0.6123 t_domain_loss: 0.6243 grl_lambda: 0.938 \n",
      "Epoch 0008 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2174 s_domain_loss: 0.6163 t_domain_loss: 0.5548 grl_lambda: 0.941 \n",
      "[11/57] class_loss: 0.2255 s_domain_loss: 0.6050 t_domain_loss: 0.6221 grl_lambda: 0.946 \n",
      "[21/57] class_loss: 0.2545 s_domain_loss: 0.5965 t_domain_loss: 0.6188 grl_lambda: 0.951 \n",
      "[31/57] class_loss: 0.2295 s_domain_loss: 0.5908 t_domain_loss: 0.5957 grl_lambda: 0.955 \n",
      "[41/57] class_loss: 0.2346 s_domain_loss: 0.6087 t_domain_loss: 0.5478 grl_lambda: 0.958 \n",
      "[51/57] class_loss: 0.2086 s_domain_loss: 0.5689 t_domain_loss: 0.5769 grl_lambda: 0.962 \n",
      "Epoch 0009 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2529 s_domain_loss: 0.5875 t_domain_loss: 0.5701 grl_lambda: 0.964 \n",
      "[11/57] class_loss: 0.2147 s_domain_loss: 0.5737 t_domain_loss: 0.5429 grl_lambda: 0.967 \n",
      "[21/57] class_loss: 0.2275 s_domain_loss: 0.5346 t_domain_loss: 0.5844 grl_lambda: 0.970 \n",
      "[31/57] class_loss: 0.2799 s_domain_loss: 0.6080 t_domain_loss: 0.5439 grl_lambda: 0.972 \n",
      "[41/57] class_loss: 0.2487 s_domain_loss: 0.5721 t_domain_loss: 0.5790 grl_lambda: 0.975 \n",
      "[51/57] class_loss: 0.2253 s_domain_loss: 0.5563 t_domain_loss: 0.5629 grl_lambda: 0.977 \n",
      "Epoch 0010 / 0010\n",
      "=================\n",
      "[1/57] class_loss: 0.2069 s_domain_loss: 0.5543 t_domain_loss: 0.5423 grl_lambda: 0.978 \n",
      "[11/57] class_loss: 0.1982 s_domain_loss: 0.5336 t_domain_loss: 0.5651 grl_lambda: 0.980 \n",
      "[21/57] class_loss: 0.2098 s_domain_loss: 0.5539 t_domain_loss: 0.5155 grl_lambda: 0.982 \n",
      "[31/57] class_loss: 0.2550 s_domain_loss: 0.5385 t_domain_loss: 0.5506 grl_lambda: 0.983 \n",
      "[41/57] class_loss: 0.2649 s_domain_loss: 0.5431 t_domain_loss: 0.5017 grl_lambda: 0.984 \n",
      "[51/57] class_loss: 0.2043 s_domain_loss: 0.4728 t_domain_loss: 0.4722 grl_lambda: 0.986 \n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch_idx in range(n_epochs):\n",
    "    print(f'Epoch {epoch_idx+1:04d} / {n_epochs:04d}', end='\\n=================\\n')\n",
    "    dl_source_iter = iter(dl_source)\n",
    "    dl_target_iter = iter(dl_target)\n",
    "    \n",
    "    for batch_idx in range(max_batches):\n",
    "        optimizer.zero_grad()\n",
    "        # Training progress and GRL Lambda\n",
    "        p = float(((batch_idx + epoch_idx * max_batches) / (n_epochs * max_batches))/2)\n",
    "        grl_lambda = 2. / (1. + np.exp(-10*p)) - 1\n",
    "        \n",
    "        # Train on source domain\n",
    "        X_s, y_s = next(dl_source_iter)\n",
    "        X_s, y_s = X_s.cuda(), y_s.cuda()\n",
    "        y_s_domain = torch.zeros(batch_size, dtype=torch.long) # generate source domain labels\n",
    "        y_s_domain = y_s_domain.cuda()\n",
    "        \n",
    "        class_pred, domain_pred = model(X_s, grl_lambda)\n",
    "        loss_s_label = loss_fn_class(class_pred, y_s)\n",
    "        loss_s_domain = loss_fn_domain(domain_pred, y_s_domain)\n",
    "        \n",
    "        # Tran on target domain\n",
    "        X_t, _ = next(dl_target_iter) # ignore target domain class labels!\n",
    "        X_t = X_t.cuda()\n",
    "        y_t_domain = torch.ones(batch_size, dtype=torch.long) # generate target domain labels\n",
    "        y_t_domain = y_t_domain.cuda()\n",
    "        \n",
    "        _, domain_pred = model(X_t, grl_lambda)\n",
    "        loss_t_domain = loss_fn_domain(domain_pred, y_t_domain)\n",
    "        \n",
    "        # Calculate total loss\n",
    "        loss = loss_t_domain + loss_s_domain + loss_s_label\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'[{batch_idx+1}/{max_batches}] '\n",
    "                  f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n",
    "                  f't_domain_loss: {loss_t_domain.item():.4f} ' f'grl_lambda: {grl_lambda:.3f} '\n",
    "                 )\n",
    "            \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0eeb04e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8192\n"
     ]
    }
   ],
   "source": [
    "ts_source = dset.MNIST(root=root, train=False, transform=tf_source, download=True)\n",
    "ts_target = MNISTMDataset(os.path.join(root, 'mnist_m', 'mnist_m_test'),\n",
    "                         os.path.join(root, 'mnist_m', 'mnist_m_test_labels.txt'),\n",
    "                         transform=tf_target)\n",
    "batch_size1 = 1024\n",
    "test_dl_source = torch.utils.data.DataLoader(ts_source, batch_size1)\n",
    "test_dl_target = torch.utils.data.DataLoader(ts_target, batch_size1)\n",
    "#dataset_first_n(ts_source,3,cmap='gray')\n",
    "#dataset_first_n(ts_target,3)\n",
    "max_batches1 = min(len(test_dl_source), len(test_dl_target))-1\n",
    "num_samples = max_batches1 * batch_size1\n",
    "print(num_samples)\n",
    "\n",
    "#batch1_s = next(iter(test_dl_source))\n",
    "\n",
    "#print(f'True class labels: {batch1_s[1]}')\n",
    "#test_class, test_domain = model(batch1_s[0])\n",
    "#print(f'test class prediction: {torch.argmax(test_class, dim=1)}, test domain prediction: {torch.argmax(test_domain, dim=1)}')\n",
    "\n",
    "#total_correct = (batch1_s[1] == torch.argmax(test_class, dim=1)).sum().item() \n",
    "#print(type(float(total_correct)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8320f0dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0001 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.9248046875, Domain Accuracry: 0.6630859375\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.214, Domain Accuracry: 0.809\n",
      "Batch 0002 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.9150390625, Domain Accuracry: 0.7119140625\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.190, Domain Accuracry: 0.786\n",
      "Batch 0003 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.923828125, Domain Accuracry: 0.69921875\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.199, Domain Accuracry: 0.783\n",
      "Batch 0004 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.9365234375, Domain Accuracry: 0.671875\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.219, Domain Accuracry: 0.783\n",
      "Batch 0005 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.9306640625, Domain Accuracry: 0.689453125\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.208, Domain Accuracry: 0.805\n",
      "Batch 0006 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.93359375, Domain Accuracry: 0.7109375\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.230, Domain Accuracry: 0.834\n",
      "Batch 0007 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.958984375, Domain Accuracry: 0.693359375\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.226, Domain Accuracry: 0.852\n",
      "Batch 0008 / 0008\n",
      "=================\n",
      "============Source Domain Inference============\n",
      "Class Accuracy: 0.890625, Domain Accuracry: 0.728515625\n",
      "============Target Domain Inference============\n",
      "Class Accuracy: 0.240, Domain Accuracry: 0.858\n",
      "+++++++++++++++Final Source Accuracy+++++++++++++++\n",
      "Class Accurary 0.927, Domain Accuracy: 0.696\n",
      "+++++++++++++++Final Target Accuracy+++++++++++++++\n",
      "Class Accurary 0.216, Domain Accuracy: 0.814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_source_iter = iter(test_dl_source)\n",
    "test_target_iter = iter(test_dl_target)\n",
    "\n",
    "s_class_labelled_correctly = 0\n",
    "s_domain_labelled_correctly = 0\n",
    "t_class_labelled_correctly = 0\n",
    "t_domain_labelled_correctly = 0\n",
    "model.eval()\n",
    "# Evaluate training\n",
    "for batch_idx in range(max_batches1):\n",
    "    print(f'Batch {batch_idx+1:04d} / {max_batches1:04d}', end='\\n=================\\n')\n",
    "    \n",
    "    # source domain\n",
    "    X_s, y_s = next(test_source_iter)\n",
    "    X_s, y_s = X_s.cuda(), y_s.cuda()\n",
    "    y_s_domain = torch.zeros(batch_size1, dtype=torch.long) # generate source domain labels   \n",
    "    y_s_domain = y_s_domain.cuda()\n",
    "    \n",
    "    # Inference Source Domain\n",
    "    Y_s_pred, Y_s_domain_pred = model(X_s)\n",
    "    correct_class_pred = float((y_s == torch.argmax(Y_s_pred, dim=1)).sum().item())\n",
    "    correct_domain_pred = float((y_s_domain == torch.argmin(Y_s_domain_pred, dim=1)).sum().item())\n",
    "    print(\"============Source Domain Inference============\")\n",
    "    print(f'Class Accuracy: {correct_class_pred/batch_size1}, Domain Accuracry: {correct_domain_pred/batch_size1}')\n",
    "    s_class_labelled_correctly += correct_class_pred\n",
    "    s_domain_labelled_correctly += correct_domain_pred\n",
    "    correct_class_pred = 0\n",
    "    correct_domain_pred = 0\n",
    "    \n",
    "    # Target domain\n",
    "    X_t, y_t = next(test_target_iter) # ignore target domain class labels!\n",
    "    X_t, y_t = X_t.cuda(), y_t.cuda()\n",
    "    y_t_domain = torch.ones(batch_size1, dtype=torch.long) # generate target domain labels\n",
    "    y_t_domain = y_t_domain.cuda()\n",
    "    \n",
    "    # Inference Target Domain\n",
    "    Y_t_pred, Y_t_domain_pred = model(X_t)\n",
    "    correct_class_pred = float((y_t == torch.argmax(Y_t_pred, dim=1)).sum().item())\n",
    "    correct_domain_pred = float((y_t_domain == torch.argmin(Y_t_domain_pred, dim=1)).sum().item())\n",
    "    print(\"============Target Domain Inference============\")\n",
    "    print(f'Class Accuracy: {correct_class_pred/batch_size1:.3f}, Domain Accuracry: {correct_domain_pred/batch_size1:.3f}')\n",
    "    t_class_labelled_correctly += correct_class_pred\n",
    "    t_domain_labelled_correctly += correct_domain_pred\n",
    "    correct_class_pred = 0\n",
    "    correct_domain_pred = 0\n",
    "    \n",
    "print(f'+++++++++++++++Final Source Accuracy+++++++++++++++')\n",
    "print(f'Class Accurary {s_class_labelled_correctly/num_samples:.3f}, Domain Accuracy: {s_domain_labelled_correctly/num_samples:.3f}')\n",
    "print(f'+++++++++++++++Final Target Accuracy+++++++++++++++')\n",
    "print(f'Class Accurary {t_class_labelled_correctly/num_samples:.3f}, Domain Accuracy: {t_domain_labelled_correctly/num_samples:.3f}')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3490d7e6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=28, interpolation=bilinear, max_size=None, antialias=None)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "63d9a457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([4, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,1,3,3)\n",
    "print(x.shape)\n",
    "y = torch.rand(4,3,3,3)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a577af3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3, 3])\n",
      "torch.Size([4, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x3 = x.expand(x.data.shape[0], 3, 3, 3)\n",
    "print(x3.shape)\n",
    "y3 = y.expand(y.data.shape[0], 3, 3, 3)\n",
    "print(y3.shape)\n",
    "#y.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "260cd3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 28, 28])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl_target))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bb36c215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4650, 0.3285],\n",
      "        [0.2892, 0.7568],\n",
      "        [0.1109, 0.1639],\n",
      "        [0.7242, 0.3260]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "6f620504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4650, 0.3285, 0.2892, 0.7568],\n",
      "        [0.1109, 0.1639, 0.7242, 0.3260]])\n"
     ]
    }
   ],
   "source": [
    "x2 = x.view(2, 4)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6be1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
